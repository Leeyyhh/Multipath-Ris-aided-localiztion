{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HUL4BN6nmIMi",
        "outputId": "785155da-9d52-43ec-8f91-56c46b0e4141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!!!! training from scratch !!!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-5ef11138ba69>:388: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "exist folder\n",
            "epoch 0   loss_test:157.32361   best_test:1000000.00000   sqrt_loss_test:12.54287   sqrt_best_test:1000.00000\n",
            "train_loss 159.80054\n",
            "epoch 20   loss_test:6.90114   best_test:157.32361   sqrt_loss_test:2.62700   sqrt_best_test:12.54287\n",
            "train_loss 6.7104554\n",
            "epoch 40   loss_test:3.74470   best_test:6.90114   sqrt_loss_test:1.93512   sqrt_best_test:2.62700\n",
            "train_loss 4.3305335\n",
            "epoch 60   loss_test:3.01084   best_test:3.74470   sqrt_loss_test:1.73518   sqrt_best_test:1.93512\n",
            "train_loss 3.286548\n",
            "epoch 80   loss_test:2.60674   best_test:3.01084   sqrt_loss_test:1.61454   sqrt_best_test:1.73518\n",
            "train_loss 2.424601\n",
            "epoch 100   loss_test:2.47117   best_test:2.60674   sqrt_loss_test:1.57200   sqrt_best_test:1.61454\n",
            "train_loss 2.3059812\n",
            "epoch 120   loss_test:2.25527   best_test:2.47117   sqrt_loss_test:1.50176   sqrt_best_test:1.57200\n",
            "train_loss 1.9938258\n",
            "epoch 140   loss_test:2.02110   best_test:2.25527   sqrt_loss_test:1.42165   sqrt_best_test:1.50176\n",
            "train_loss 2.1329215\n",
            "epoch 160   loss_test:1.84529   best_test:2.02110   sqrt_loss_test:1.35841   sqrt_best_test:1.42165\n",
            "train_loss 1.8574471\n",
            "epoch 180   loss_test:1.89199   best_test:1.84529   sqrt_loss_test:1.37550   sqrt_best_test:1.35841\n",
            "train_loss 1.897348\n",
            "epoch 200   loss_test:1.69989   best_test:1.84529   sqrt_loss_test:1.30380   sqrt_best_test:1.35841\n",
            "train_loss 1.749507\n",
            "epoch 220   loss_test:1.62769   best_test:1.69989   sqrt_loss_test:1.27581   sqrt_best_test:1.30380\n",
            "train_loss 1.63726\n",
            "epoch 240   loss_test:1.63602   best_test:1.62769   sqrt_loss_test:1.27907   sqrt_best_test:1.27581\n",
            "train_loss 1.5901649\n",
            "epoch 260   loss_test:1.44710   best_test:1.62769   sqrt_loss_test:1.20296   sqrt_best_test:1.27581\n",
            "train_loss 1.3511004\n",
            "epoch 280   loss_test:1.40217   best_test:1.44710   sqrt_loss_test:1.18413   sqrt_best_test:1.20296\n",
            "train_loss 1.5809691\n",
            "epoch 300   loss_test:1.39111   best_test:1.40217   sqrt_loss_test:1.17946   sqrt_best_test:1.18413\n",
            "train_loss 1.382912\n",
            "epoch 320   loss_test:1.24390   best_test:1.39111   sqrt_loss_test:1.11530   sqrt_best_test:1.17946\n",
            "train_loss 1.2902937\n",
            "epoch 340   loss_test:1.20491   best_test:1.24390   sqrt_loss_test:1.09768   sqrt_best_test:1.11530\n",
            "train_loss 1.309964\n",
            "epoch 360   loss_test:1.19832   best_test:1.20491   sqrt_loss_test:1.09468   sqrt_best_test:1.09768\n",
            "train_loss 1.2846459\n",
            "epoch 380   loss_test:1.18321   best_test:1.19832   sqrt_loss_test:1.08775   sqrt_best_test:1.09468\n",
            "train_loss 1.1641195\n",
            "epoch 400   loss_test:1.12924   best_test:1.18321   sqrt_loss_test:1.06266   sqrt_best_test:1.08775\n",
            "train_loss 1.1664373\n",
            "epoch 420   loss_test:1.07270   best_test:1.12924   sqrt_loss_test:1.03571   sqrt_best_test:1.06266\n",
            "train_loss 1.1936553\n",
            "epoch 440   loss_test:1.02277   best_test:1.07270   sqrt_loss_test:1.01132   sqrt_best_test:1.03571\n",
            "train_loss 1.099317\n",
            "epoch 460   loss_test:1.05481   best_test:1.02277   sqrt_loss_test:1.02704   sqrt_best_test:1.01132\n",
            "train_loss 1.0816813\n",
            "epoch 480   loss_test:1.07112   best_test:1.02277   sqrt_loss_test:1.03495   sqrt_best_test:1.01132\n",
            "train_loss 1.033814\n",
            "epoch 500   loss_test:1.06512   best_test:1.02277   sqrt_loss_test:1.03205   sqrt_best_test:1.01132\n",
            "train_loss 1.1279455\n",
            "epoch 520   loss_test:1.02326   best_test:1.02277   sqrt_loss_test:1.01156   sqrt_best_test:1.01132\n",
            "train_loss 1.1356214\n",
            "epoch 540   loss_test:1.02444   best_test:1.02277   sqrt_loss_test:1.01215   sqrt_best_test:1.01132\n",
            "train_loss 1.0357685\n",
            "epoch 560   loss_test:0.97793   best_test:1.02277   sqrt_loss_test:0.98890   sqrt_best_test:1.01132\n",
            "train_loss 0.96230334\n",
            "epoch 580   loss_test:0.95342   best_test:0.97793   sqrt_loss_test:0.97643   sqrt_best_test:0.98890\n",
            "train_loss 0.9817666\n",
            "epoch 600   loss_test:1.01778   best_test:0.95342   sqrt_loss_test:1.00885   sqrt_best_test:0.97643\n",
            "train_loss 0.9896777\n",
            "epoch 620   loss_test:0.92006   best_test:0.95342   sqrt_loss_test:0.95920   sqrt_best_test:0.97643\n",
            "train_loss 0.9473592\n",
            "epoch 640   loss_test:0.98633   best_test:0.92006   sqrt_loss_test:0.99314   sqrt_best_test:0.95920\n",
            "train_loss 1.0489042\n",
            "epoch 660   loss_test:0.85849   best_test:0.92006   sqrt_loss_test:0.92655   sqrt_best_test:0.95920\n",
            "train_loss 0.9398478\n",
            "epoch 680   loss_test:0.87460   best_test:0.85849   sqrt_loss_test:0.93520   sqrt_best_test:0.92655\n",
            "train_loss 0.9024794\n",
            "epoch 700   loss_test:0.78003   best_test:0.85849   sqrt_loss_test:0.88319   sqrt_best_test:0.92655\n",
            "train_loss 0.87961555\n",
            "epoch 720   loss_test:0.85788   best_test:0.78003   sqrt_loss_test:0.92622   sqrt_best_test:0.88319\n",
            "train_loss 0.89946187\n",
            "epoch 740   loss_test:0.84393   best_test:0.78003   sqrt_loss_test:0.91866   sqrt_best_test:0.88319\n",
            "train_loss 0.7856511\n",
            "epoch 760   loss_test:0.73517   best_test:0.78003   sqrt_loss_test:0.85742   sqrt_best_test:0.88319\n",
            "train_loss 0.7507727\n",
            "epoch 780   loss_test:0.82511   best_test:0.73517   sqrt_loss_test:0.90835   sqrt_best_test:0.85742\n",
            "train_loss 0.7478705\n",
            "epoch 800   loss_test:0.73802   best_test:0.73517   sqrt_loss_test:0.85908   sqrt_best_test:0.85742\n",
            "train_loss 0.7650751\n",
            "epoch 820   loss_test:0.75384   best_test:0.73517   sqrt_loss_test:0.86824   sqrt_best_test:0.85742\n",
            "train_loss 0.7509717\n",
            "epoch 840   loss_test:0.75849   best_test:0.73517   sqrt_loss_test:0.87091   sqrt_best_test:0.85742\n",
            "train_loss 0.7872899\n",
            "epoch 860   loss_test:0.76460   best_test:0.73517   sqrt_loss_test:0.87442   sqrt_best_test:0.85742\n",
            "train_loss 0.7253039\n",
            "epoch 880   loss_test:0.73059   best_test:0.73517   sqrt_loss_test:0.85474   sqrt_best_test:0.85742\n",
            "train_loss 0.72609144\n",
            "epoch 900   loss_test:0.69637   best_test:0.73059   sqrt_loss_test:0.83449   sqrt_best_test:0.85474\n",
            "train_loss 0.7428606\n",
            "epoch 920   loss_test:0.62097   best_test:0.69637   sqrt_loss_test:0.78802   sqrt_best_test:0.83449\n",
            "train_loss 0.67171407\n",
            "epoch 940   loss_test:0.68823   best_test:0.62097   sqrt_loss_test:0.82960   sqrt_best_test:0.78802\n",
            "train_loss 0.6962017\n",
            "epoch 960   loss_test:0.61945   best_test:0.62097   sqrt_loss_test:0.78705   sqrt_best_test:0.78802\n",
            "train_loss 0.6155349\n",
            "epoch 980   loss_test:0.59116   best_test:0.61945   sqrt_loss_test:0.76887   sqrt_best_test:0.78705\n",
            "train_loss 0.6360363\n",
            "epoch 1000   loss_test:0.60163   best_test:0.59116   sqrt_loss_test:0.77565   sqrt_best_test:0.76887\n",
            "train_loss 0.6344275\n",
            "epoch 1020   loss_test:0.61000   best_test:0.59116   sqrt_loss_test:0.78103   sqrt_best_test:0.76887\n",
            "train_loss 0.6285661\n",
            "epoch 1040   loss_test:0.61691   best_test:0.59116   sqrt_loss_test:0.78544   sqrt_best_test:0.76887\n",
            "train_loss 0.5766939\n",
            "epoch 1060   loss_test:0.57914   best_test:0.59116   sqrt_loss_test:0.76101   sqrt_best_test:0.76887\n",
            "train_loss 0.57975936\n",
            "epoch 1080   loss_test:0.53805   best_test:0.57914   sqrt_loss_test:0.73352   sqrt_best_test:0.76101\n",
            "train_loss 0.55225927\n",
            "epoch 1100   loss_test:0.56917   best_test:0.53805   sqrt_loss_test:0.75443   sqrt_best_test:0.73352\n",
            "train_loss 0.5621236\n",
            "epoch 1120   loss_test:0.59625   best_test:0.53805   sqrt_loss_test:0.77217   sqrt_best_test:0.73352\n",
            "train_loss 0.46453568\n",
            "epoch 1140   loss_test:0.53595   best_test:0.53805   sqrt_loss_test:0.73209   sqrt_best_test:0.73352\n",
            "train_loss 0.5162883\n",
            "epoch 1160   loss_test:0.51281   best_test:0.53595   sqrt_loss_test:0.71611   sqrt_best_test:0.73209\n",
            "train_loss 0.4911896\n",
            "epoch 1180   loss_test:0.53741   best_test:0.51281   sqrt_loss_test:0.73308   sqrt_best_test:0.71611\n",
            "train_loss 0.54194456\n",
            "epoch 1200   loss_test:0.49656   best_test:0.51281   sqrt_loss_test:0.70467   sqrt_best_test:0.71611\n",
            "train_loss 0.47797143\n",
            "epoch 1220   loss_test:0.47476   best_test:0.49656   sqrt_loss_test:0.68903   sqrt_best_test:0.70467\n",
            "train_loss 0.4708207\n",
            "epoch 1240   loss_test:0.47961   best_test:0.47476   sqrt_loss_test:0.69254   sqrt_best_test:0.68903\n",
            "train_loss 0.46445715\n",
            "epoch 1260   loss_test:0.44992   best_test:0.47476   sqrt_loss_test:0.67076   sqrt_best_test:0.68903\n",
            "train_loss 0.47697455\n",
            "epoch 1280   loss_test:0.49130   best_test:0.44992   sqrt_loss_test:0.70093   sqrt_best_test:0.67076\n",
            "train_loss 0.46173587\n",
            "epoch 1300   loss_test:0.43887   best_test:0.44992   sqrt_loss_test:0.66247   sqrt_best_test:0.67076\n",
            "train_loss 0.44844493\n",
            "epoch 1320   loss_test:0.41046   best_test:0.43887   sqrt_loss_test:0.64067   sqrt_best_test:0.66247\n",
            "train_loss 0.43890035\n",
            "epoch 1340   loss_test:0.43293   best_test:0.41046   sqrt_loss_test:0.65797   sqrt_best_test:0.64067\n",
            "train_loss 0.43217003\n",
            "epoch 1360   loss_test:0.43800   best_test:0.41046   sqrt_loss_test:0.66182   sqrt_best_test:0.64067\n",
            "train_loss 0.43215898\n",
            "epoch 1380   loss_test:0.42764   best_test:0.41046   sqrt_loss_test:0.65394   sqrt_best_test:0.64067\n",
            "train_loss 0.40972555\n",
            "epoch 1400   loss_test:0.45370   best_test:0.41046   sqrt_loss_test:0.67357   sqrt_best_test:0.64067\n",
            "train_loss 0.42891902\n",
            "epoch 1420   loss_test:0.42671   best_test:0.41046   sqrt_loss_test:0.65323   sqrt_best_test:0.64067\n",
            "train_loss 0.39968124\n",
            "epoch 1440   loss_test:0.41701   best_test:0.41046   sqrt_loss_test:0.64577   sqrt_best_test:0.64067\n",
            "train_loss 0.4287727\n",
            "epoch 1460   loss_test:0.41354   best_test:0.41046   sqrt_loss_test:0.64307   sqrt_best_test:0.64067\n",
            "train_loss 0.40229318\n",
            "epoch 1480   loss_test:0.38139   best_test:0.41046   sqrt_loss_test:0.61757   sqrt_best_test:0.64067\n",
            "train_loss 0.37355798\n",
            "epoch 1500   loss_test:0.38723   best_test:0.38139   sqrt_loss_test:0.62227   sqrt_best_test:0.61757\n",
            "train_loss 0.4016406\n",
            "epoch 1520   loss_test:0.38904   best_test:0.38139   sqrt_loss_test:0.62373   sqrt_best_test:0.61757\n",
            "train_loss 0.39218885\n",
            "epoch 1540   loss_test:0.41656   best_test:0.38139   sqrt_loss_test:0.64541   sqrt_best_test:0.61757\n",
            "train_loss 0.36076275\n",
            "epoch 1560   loss_test:0.38937   best_test:0.38139   sqrt_loss_test:0.62400   sqrt_best_test:0.61757\n",
            "train_loss 0.4332431\n",
            "epoch 1580   loss_test:0.40416   best_test:0.38139   sqrt_loss_test:0.63574   sqrt_best_test:0.61757\n",
            "train_loss 0.37289402\n",
            "epoch 1600   loss_test:0.38382   best_test:0.38139   sqrt_loss_test:0.61954   sqrt_best_test:0.61757\n",
            "train_loss 0.36100742\n",
            "epoch 1620   loss_test:0.39514   best_test:0.38139   sqrt_loss_test:0.62860   sqrt_best_test:0.61757\n",
            "train_loss 0.40201047\n",
            "epoch 1640   loss_test:0.37674   best_test:0.38139   sqrt_loss_test:0.61379   sqrt_best_test:0.61757\n",
            "train_loss 0.36504805\n",
            "epoch 1660   loss_test:0.35047   best_test:0.37674   sqrt_loss_test:0.59201   sqrt_best_test:0.61379\n",
            "train_loss 0.38734517\n",
            "epoch 1680   loss_test:0.36635   best_test:0.35047   sqrt_loss_test:0.60527   sqrt_best_test:0.59201\n",
            "train_loss 0.34531477\n",
            "epoch 1700   loss_test:0.36985   best_test:0.35047   sqrt_loss_test:0.60815   sqrt_best_test:0.59201\n",
            "train_loss 0.38375062\n",
            "epoch 1720   loss_test:0.34475   best_test:0.35047   sqrt_loss_test:0.58715   sqrt_best_test:0.59201\n",
            "train_loss 0.36203215\n",
            "epoch 1740   loss_test:0.36578   best_test:0.34475   sqrt_loss_test:0.60480   sqrt_best_test:0.58715\n",
            "train_loss 0.34467003\n",
            "epoch 1760   loss_test:0.39379   best_test:0.34475   sqrt_loss_test:0.62753   sqrt_best_test:0.58715\n",
            "train_loss 0.34848255\n",
            "epoch 1780   loss_test:0.36090   best_test:0.34475   sqrt_loss_test:0.60075   sqrt_best_test:0.58715\n",
            "train_loss 0.34371486\n",
            "epoch 1800   loss_test:0.35111   best_test:0.34475   sqrt_loss_test:0.59255   sqrt_best_test:0.58715\n",
            "train_loss 0.37198627\n",
            "epoch 1820   loss_test:0.34343   best_test:0.34475   sqrt_loss_test:0.58603   sqrt_best_test:0.58715\n",
            "train_loss 0.38922018\n",
            "epoch 1840   loss_test:0.34899   best_test:0.34343   sqrt_loss_test:0.59075   sqrt_best_test:0.58603\n",
            "train_loss 0.3263985\n",
            "epoch 1860   loss_test:0.32701   best_test:0.34343   sqrt_loss_test:0.57185   sqrt_best_test:0.58603\n",
            "train_loss 0.3205434\n",
            "epoch 1880   loss_test:0.35275   best_test:0.32701   sqrt_loss_test:0.59393   sqrt_best_test:0.57185\n",
            "train_loss 0.3783152\n",
            "epoch 1900   loss_test:0.34208   best_test:0.32701   sqrt_loss_test:0.58488   sqrt_best_test:0.57185\n",
            "train_loss 0.33078134\n",
            "epoch 1920   loss_test:0.35224   best_test:0.32701   sqrt_loss_test:0.59350   sqrt_best_test:0.57185\n",
            "train_loss 0.41181323\n",
            "epoch 1940   loss_test:0.35379   best_test:0.32701   sqrt_loss_test:0.59480   sqrt_best_test:0.57185\n",
            "train_loss 0.2973961\n",
            "epoch 1960   loss_test:0.36619   best_test:0.32701   sqrt_loss_test:0.60514   sqrt_best_test:0.57185\n",
            "train_loss 0.32151827\n",
            "epoch 1980   loss_test:0.35038   best_test:0.32701   sqrt_loss_test:0.59193   sqrt_best_test:0.57185\n",
            "train_loss 0.34794974\n",
            "epoch 2000   loss_test:0.31949   best_test:0.32701   sqrt_loss_test:0.56523   sqrt_best_test:0.57185\n",
            "train_loss 0.3332128\n",
            "epoch 2020   loss_test:0.33974   best_test:0.31949   sqrt_loss_test:0.58287   sqrt_best_test:0.56523\n",
            "train_loss 0.31082135\n",
            "epoch 2040   loss_test:0.34995   best_test:0.31949   sqrt_loss_test:0.59157   sqrt_best_test:0.56523\n",
            "train_loss 0.31776363\n",
            "epoch 2060   loss_test:0.35779   best_test:0.31949   sqrt_loss_test:0.59815   sqrt_best_test:0.56523\n",
            "train_loss 0.34485903\n",
            "epoch 2080   loss_test:0.40389   best_test:0.31949   sqrt_loss_test:0.63552   sqrt_best_test:0.56523\n",
            "train_loss 0.29565358\n",
            "epoch 2100   loss_test:0.31033   best_test:0.31949   sqrt_loss_test:0.55708   sqrt_best_test:0.56523\n",
            "train_loss 0.30662125\n",
            "epoch 2120   loss_test:0.32990   best_test:0.31033   sqrt_loss_test:0.57437   sqrt_best_test:0.55708\n",
            "train_loss 0.3231853\n",
            "epoch 2140   loss_test:0.33137   best_test:0.31033   sqrt_loss_test:0.57565   sqrt_best_test:0.55708\n",
            "train_loss 0.3714643\n",
            "epoch 2160   loss_test:0.31665   best_test:0.31033   sqrt_loss_test:0.56272   sqrt_best_test:0.55708\n",
            "train_loss 0.3196684\n",
            "epoch 2180   loss_test:0.35378   best_test:0.31033   sqrt_loss_test:0.59479   sqrt_best_test:0.55708\n",
            "train_loss 0.29263437\n",
            "epoch 2200   loss_test:0.37335   best_test:0.31033   sqrt_loss_test:0.61102   sqrt_best_test:0.55708\n",
            "train_loss 0.30799568\n",
            "epoch 2220   loss_test:0.32341   best_test:0.31033   sqrt_loss_test:0.56869   sqrt_best_test:0.55708\n",
            "train_loss 0.3239832\n",
            "epoch 2240   loss_test:0.30397   best_test:0.31033   sqrt_loss_test:0.55133   sqrt_best_test:0.55708\n",
            "train_loss 0.30039936\n",
            "epoch 2260   loss_test:0.32672   best_test:0.30397   sqrt_loss_test:0.57159   sqrt_best_test:0.55133\n",
            "train_loss 0.31509534\n",
            "epoch 2280   loss_test:0.28329   best_test:0.30397   sqrt_loss_test:0.53225   sqrt_best_test:0.55133\n",
            "train_loss 0.29535523\n",
            "epoch 2300   loss_test:0.30900   best_test:0.28329   sqrt_loss_test:0.55588   sqrt_best_test:0.53225\n",
            "train_loss 0.3032261\n",
            "epoch 2320   loss_test:0.31850   best_test:0.28329   sqrt_loss_test:0.56436   sqrt_best_test:0.53225\n",
            "train_loss 0.30900803\n",
            "epoch 2340   loss_test:0.32010   best_test:0.28329   sqrt_loss_test:0.56577   sqrt_best_test:0.53225\n",
            "train_loss 0.3028487\n",
            "epoch 2360   loss_test:0.31762   best_test:0.28329   sqrt_loss_test:0.56358   sqrt_best_test:0.53225\n",
            "train_loss 0.29275745\n",
            "epoch 2380   loss_test:0.30071   best_test:0.28329   sqrt_loss_test:0.54837   sqrt_best_test:0.53225\n",
            "train_loss 0.32392663\n",
            "epoch 2400   loss_test:0.32732   best_test:0.28329   sqrt_loss_test:0.57212   sqrt_best_test:0.53225\n",
            "train_loss 0.31072792\n",
            "epoch 2420   loss_test:0.30528   best_test:0.28329   sqrt_loss_test:0.55252   sqrt_best_test:0.53225\n",
            "train_loss 0.30277538\n",
            "epoch 2440   loss_test:0.31639   best_test:0.28329   sqrt_loss_test:0.56249   sqrt_best_test:0.53225\n",
            "train_loss 0.32510334\n",
            "epoch 2460   loss_test:0.30738   best_test:0.28329   sqrt_loss_test:0.55441   sqrt_best_test:0.53225\n",
            "train_loss 0.28309825\n",
            "epoch 2480   loss_test:0.29751   best_test:0.28329   sqrt_loss_test:0.54545   sqrt_best_test:0.53225\n",
            "train_loss 0.27436292\n",
            "epoch 2500   loss_test:0.33869   best_test:0.28329   sqrt_loss_test:0.58197   sqrt_best_test:0.53225\n",
            "train_loss 0.34662125\n",
            "epoch 2520   loss_test:0.30655   best_test:0.28329   sqrt_loss_test:0.55367   sqrt_best_test:0.53225\n",
            "train_loss 0.31114835\n",
            "epoch 2540   loss_test:0.30113   best_test:0.28329   sqrt_loss_test:0.54875   sqrt_best_test:0.53225\n",
            "train_loss 0.28275022\n",
            "epoch 2560   loss_test:0.30944   best_test:0.28329   sqrt_loss_test:0.55628   sqrt_best_test:0.53225\n",
            "train_loss 0.30556607\n",
            "epoch 2580   loss_test:0.30559   best_test:0.28329   sqrt_loss_test:0.55280   sqrt_best_test:0.53225\n",
            "train_loss 0.26429367\n",
            "epoch 2600   loss_test:0.31143   best_test:0.28329   sqrt_loss_test:0.55806   sqrt_best_test:0.53225\n",
            "train_loss 0.27744707\n",
            "epoch 2620   loss_test:0.31812   best_test:0.28329   sqrt_loss_test:0.56402   sqrt_best_test:0.53225\n",
            "train_loss 0.28891394\n",
            "epoch 2640   loss_test:0.30647   best_test:0.28329   sqrt_loss_test:0.55360   sqrt_best_test:0.53225\n",
            "train_loss 0.30325666\n",
            "epoch 2660   loss_test:0.31705   best_test:0.28329   sqrt_loss_test:0.56307   sqrt_best_test:0.53225\n",
            "train_loss 0.28471345\n",
            "epoch 2680   loss_test:0.30441   best_test:0.28329   sqrt_loss_test:0.55173   sqrt_best_test:0.53225\n",
            "train_loss 0.28426856\n",
            "epoch 2700   loss_test:0.31535   best_test:0.28329   sqrt_loss_test:0.56156   sqrt_best_test:0.53225\n",
            "train_loss 0.27962926\n",
            "epoch 2720   loss_test:0.31868   best_test:0.28329   sqrt_loss_test:0.56451   sqrt_best_test:0.53225\n",
            "train_loss 0.30459464\n",
            "epoch 2740   loss_test:0.31030   best_test:0.28329   sqrt_loss_test:0.55704   sqrt_best_test:0.53225\n",
            "train_loss 0.27673787\n",
            "epoch 2760   loss_test:0.28892   best_test:0.28329   sqrt_loss_test:0.53751   sqrt_best_test:0.53225\n",
            "train_loss 0.28554583\n",
            "epoch 2780   loss_test:0.31159   best_test:0.28329   sqrt_loss_test:0.55820   sqrt_best_test:0.53225\n",
            "train_loss 0.29395628\n",
            "epoch 2800   loss_test:0.32498   best_test:0.28329   sqrt_loss_test:0.57007   sqrt_best_test:0.53225\n",
            "train_loss 0.28948772\n",
            "epoch 2820   loss_test:0.28439   best_test:0.28329   sqrt_loss_test:0.53328   sqrt_best_test:0.53225\n",
            "train_loss 0.26328832\n",
            "epoch 2840   loss_test:0.27461   best_test:0.28329   sqrt_loss_test:0.52403   sqrt_best_test:0.53225\n",
            "train_loss 0.27691388\n",
            "epoch 2860   loss_test:0.28323   best_test:0.27461   sqrt_loss_test:0.53219   sqrt_best_test:0.52403\n",
            "train_loss 0.25474247\n",
            "epoch 2880   loss_test:0.28727   best_test:0.27461   sqrt_loss_test:0.53597   sqrt_best_test:0.52403\n",
            "train_loss 0.31901965\n",
            "epoch 2900   loss_test:0.27105   best_test:0.27461   sqrt_loss_test:0.52062   sqrt_best_test:0.52403\n",
            "train_loss 0.28048432\n",
            "epoch 2920   loss_test:0.28326   best_test:0.27105   sqrt_loss_test:0.53222   sqrt_best_test:0.52062\n",
            "train_loss 0.27826542\n",
            "epoch 2940   loss_test:0.27827   best_test:0.27105   sqrt_loss_test:0.52751   sqrt_best_test:0.52062\n",
            "train_loss 0.27392063\n",
            "epoch 2960   loss_test:0.28679   best_test:0.27105   sqrt_loss_test:0.53552   sqrt_best_test:0.52062\n",
            "train_loss 0.25655666\n",
            "epoch 2980   loss_test:0.28567   best_test:0.27105   sqrt_loss_test:0.53448   sqrt_best_test:0.52062\n",
            "train_loss 0.25277454\n",
            "epoch 3000   loss_test:0.27775   best_test:0.27105   sqrt_loss_test:0.52702   sqrt_best_test:0.52062\n",
            "train_loss 0.27979124\n",
            "epoch 3020   loss_test:0.27600   best_test:0.27105   sqrt_loss_test:0.52535   sqrt_best_test:0.52062\n",
            "train_loss 0.25987396\n",
            "epoch 3040   loss_test:0.27331   best_test:0.27105   sqrt_loss_test:0.52279   sqrt_best_test:0.52062\n",
            "train_loss 0.2784347\n",
            "epoch 3060   loss_test:0.31448   best_test:0.27105   sqrt_loss_test:0.56079   sqrt_best_test:0.52062\n",
            "train_loss 0.2791723\n",
            "epoch 3080   loss_test:0.29117   best_test:0.27105   sqrt_loss_test:0.53960   sqrt_best_test:0.52062\n",
            "train_loss 0.28245163\n",
            "epoch 3100   loss_test:0.28895   best_test:0.27105   sqrt_loss_test:0.53754   sqrt_best_test:0.52062\n",
            "train_loss 0.27357158\n",
            "epoch 3120   loss_test:0.27967   best_test:0.27105   sqrt_loss_test:0.52884   sqrt_best_test:0.52062\n",
            "train_loss 0.2830658\n",
            "epoch 3140   loss_test:0.27907   best_test:0.27105   sqrt_loss_test:0.52827   sqrt_best_test:0.52062\n",
            "train_loss 0.2944724\n",
            "epoch 3160   loss_test:0.29555   best_test:0.27105   sqrt_loss_test:0.54364   sqrt_best_test:0.52062\n",
            "train_loss 0.29652393\n",
            "epoch 3180   loss_test:0.27547   best_test:0.27105   sqrt_loss_test:0.52485   sqrt_best_test:0.52062\n",
            "train_loss 0.29848832\n",
            "epoch 3200   loss_test:0.27008   best_test:0.27105   sqrt_loss_test:0.51969   sqrt_best_test:0.52062\n",
            "train_loss 0.2605672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3220   loss_test:0.27972   best_test:0.27008   sqrt_loss_test:0.52889   sqrt_best_test:0.51969\n",
            "train_loss 0.28259918\n",
            "epoch 3240   loss_test:0.28382   best_test:0.27008   sqrt_loss_test:0.53274   sqrt_best_test:0.51969\n",
            "train_loss 0.26855817\n",
            "epoch 3260   loss_test:0.28273   best_test:0.27008   sqrt_loss_test:0.53173   sqrt_best_test:0.51969\n",
            "train_loss 0.28028867\n",
            "epoch 3280   loss_test:0.26150   best_test:0.27008   sqrt_loss_test:0.51137   sqrt_best_test:0.51969\n",
            "train_loss 0.2684714\n",
            "epoch 3300   loss_test:0.27119   best_test:0.26150   sqrt_loss_test:0.52076   sqrt_best_test:0.51137\n",
            "train_loss 0.26454452\n",
            "epoch 3320   loss_test:0.30079   best_test:0.26150   sqrt_loss_test:0.54844   sqrt_best_test:0.51137\n",
            "train_loss 0.24834387\n",
            "epoch 3340   loss_test:0.29658   best_test:0.26150   sqrt_loss_test:0.54459   sqrt_best_test:0.51137\n",
            "train_loss 0.26530913\n",
            "epoch 3360   loss_test:0.27867   best_test:0.26150   sqrt_loss_test:0.52789   sqrt_best_test:0.51137\n",
            "train_loss 0.2671954\n",
            "epoch 3380   loss_test:0.28325   best_test:0.26150   sqrt_loss_test:0.53221   sqrt_best_test:0.51137\n",
            "train_loss 0.25235215\n",
            "epoch 3400   loss_test:0.28111   best_test:0.26150   sqrt_loss_test:0.53019   sqrt_best_test:0.51137\n",
            "train_loss 0.2831524\n",
            "epoch 3420   loss_test:0.26692   best_test:0.26150   sqrt_loss_test:0.51664   sqrt_best_test:0.51137\n",
            "train_loss 0.24484879\n",
            "epoch 3440   loss_test:0.30137   best_test:0.26150   sqrt_loss_test:0.54897   sqrt_best_test:0.51137\n",
            "train_loss 0.27931815\n",
            "epoch 3460   loss_test:0.28471   best_test:0.26150   sqrt_loss_test:0.53358   sqrt_best_test:0.51137\n",
            "train_loss 0.24314578\n",
            "epoch 3480   loss_test:0.29959   best_test:0.26150   sqrt_loss_test:0.54734   sqrt_best_test:0.51137\n",
            "train_loss 0.25543335\n",
            "epoch 3500   loss_test:0.27800   best_test:0.26150   sqrt_loss_test:0.52726   sqrt_best_test:0.51137\n",
            "train_loss 0.29078034\n",
            "epoch 3520   loss_test:0.29091   best_test:0.26150   sqrt_loss_test:0.53936   sqrt_best_test:0.51137\n",
            "train_loss 0.24752453\n",
            "epoch 3540   loss_test:0.28434   best_test:0.26150   sqrt_loss_test:0.53323   sqrt_best_test:0.51137\n",
            "train_loss 0.25836802\n",
            "epoch 3560   loss_test:0.28283   best_test:0.26150   sqrt_loss_test:0.53182   sqrt_best_test:0.51137\n",
            "train_loss 0.2668864\n",
            "epoch 3580   loss_test:0.28564   best_test:0.26150   sqrt_loss_test:0.53445   sqrt_best_test:0.51137\n",
            "train_loss 0.254297\n",
            "epoch 3600   loss_test:0.28422   best_test:0.26150   sqrt_loss_test:0.53313   sqrt_best_test:0.51137\n",
            "train_loss 0.25342616\n",
            "epoch 3620   loss_test:0.27124   best_test:0.26150   sqrt_loss_test:0.52080   sqrt_best_test:0.51137\n",
            "train_loss 0.23100416\n",
            "epoch 3640   loss_test:0.25936   best_test:0.26150   sqrt_loss_test:0.50927   sqrt_best_test:0.51137\n",
            "train_loss 0.26378763\n",
            "epoch 3660   loss_test:0.26263   best_test:0.25936   sqrt_loss_test:0.51248   sqrt_best_test:0.50927\n",
            "train_loss 0.2651326\n",
            "epoch 3680   loss_test:0.27106   best_test:0.25936   sqrt_loss_test:0.52064   sqrt_best_test:0.50927\n",
            "train_loss 0.25505048\n",
            "epoch 3700   loss_test:0.25978   best_test:0.25936   sqrt_loss_test:0.50969   sqrt_best_test:0.50927\n",
            "train_loss 0.2647881\n",
            "epoch 3720   loss_test:0.26228   best_test:0.25936   sqrt_loss_test:0.51213   sqrt_best_test:0.50927\n",
            "train_loss 0.26224026\n",
            "epoch 3740   loss_test:0.26402   best_test:0.25936   sqrt_loss_test:0.51383   sqrt_best_test:0.50927\n",
            "train_loss 0.26610428\n",
            "epoch 3760   loss_test:0.26095   best_test:0.25936   sqrt_loss_test:0.51083   sqrt_best_test:0.50927\n",
            "train_loss 0.24829827\n",
            "epoch 3780   loss_test:0.23819   best_test:0.25936   sqrt_loss_test:0.48805   sqrt_best_test:0.50927\n",
            "train_loss 0.24653189\n",
            "epoch 3800   loss_test:0.24052   best_test:0.23819   sqrt_loss_test:0.49042   sqrt_best_test:0.48805\n",
            "train_loss 0.24399796\n",
            "epoch 3820   loss_test:0.29054   best_test:0.23819   sqrt_loss_test:0.53901   sqrt_best_test:0.48805\n",
            "train_loss 0.27411675\n",
            "epoch 3840   loss_test:0.24960   best_test:0.23819   sqrt_loss_test:0.49960   sqrt_best_test:0.48805\n",
            "train_loss 0.2732011\n",
            "epoch 3860   loss_test:0.29283   best_test:0.23819   sqrt_loss_test:0.54114   sqrt_best_test:0.48805\n",
            "train_loss 0.25428203\n",
            "epoch 3880   loss_test:0.29521   best_test:0.23819   sqrt_loss_test:0.54333   sqrt_best_test:0.48805\n",
            "train_loss 0.26252562\n",
            "epoch 3900   loss_test:0.27647   best_test:0.23819   sqrt_loss_test:0.52580   sqrt_best_test:0.48805\n",
            "train_loss 0.25395074\n",
            "epoch 3920   loss_test:0.27466   best_test:0.23819   sqrt_loss_test:0.52408   sqrt_best_test:0.48805\n",
            "train_loss 0.2506821\n",
            "epoch 3940   loss_test:0.25072   best_test:0.23819   sqrt_loss_test:0.50072   sqrt_best_test:0.48805\n",
            "train_loss 0.284045\n",
            "epoch 3960   loss_test:0.24903   best_test:0.23819   sqrt_loss_test:0.49903   sqrt_best_test:0.48805\n",
            "train_loss 0.25262642\n",
            "epoch 3980   loss_test:0.25134   best_test:0.23819   sqrt_loss_test:0.50134   sqrt_best_test:0.48805\n",
            "train_loss 0.2600265\n",
            "epoch 4000   loss_test:0.27274   best_test:0.23819   sqrt_loss_test:0.52225   sqrt_best_test:0.48805\n",
            "train_loss 0.27101913\n",
            "epoch 4020   loss_test:0.27058   best_test:0.23819   sqrt_loss_test:0.52018   sqrt_best_test:0.48805\n",
            "train_loss 0.24606189\n",
            "epoch 4040   loss_test:0.27614   best_test:0.23819   sqrt_loss_test:0.52549   sqrt_best_test:0.48805\n",
            "train_loss 0.24970499\n",
            "epoch 4060   loss_test:0.24659   best_test:0.23819   sqrt_loss_test:0.49658   sqrt_best_test:0.48805\n",
            "train_loss 0.25583646\n",
            "epoch 4080   loss_test:0.27453   best_test:0.23819   sqrt_loss_test:0.52395   sqrt_best_test:0.48805\n",
            "train_loss 0.24069726\n",
            "epoch 4100   loss_test:0.27246   best_test:0.23819   sqrt_loss_test:0.52198   sqrt_best_test:0.48805\n",
            "train_loss 0.26095197\n",
            "epoch 4120   loss_test:0.27612   best_test:0.23819   sqrt_loss_test:0.52547   sqrt_best_test:0.48805\n",
            "train_loss 0.25367483\n",
            "epoch 4140   loss_test:0.23404   best_test:0.23819   sqrt_loss_test:0.48378   sqrt_best_test:0.48805\n",
            "train_loss 0.24280658\n",
            "epoch 4160   loss_test:0.25149   best_test:0.23404   sqrt_loss_test:0.50148   sqrt_best_test:0.48378\n",
            "train_loss 0.2445361\n",
            "epoch 4180   loss_test:0.25788   best_test:0.23404   sqrt_loss_test:0.50782   sqrt_best_test:0.48378\n",
            "train_loss 0.24060151\n",
            "epoch 4200   loss_test:0.23697   best_test:0.23404   sqrt_loss_test:0.48680   sqrt_best_test:0.48378\n",
            "train_loss 0.25334048\n",
            "epoch 4220   loss_test:0.25820   best_test:0.23404   sqrt_loss_test:0.50813   sqrt_best_test:0.48378\n",
            "train_loss 0.262995\n",
            "epoch 4240   loss_test:0.24265   best_test:0.23404   sqrt_loss_test:0.49260   sqrt_best_test:0.48378\n",
            "train_loss 0.25019535\n",
            "epoch 4260   loss_test:0.24851   best_test:0.23404   sqrt_loss_test:0.49850   sqrt_best_test:0.48378\n",
            "train_loss 0.26273125\n",
            "epoch 4280   loss_test:0.24643   best_test:0.23404   sqrt_loss_test:0.49642   sqrt_best_test:0.48378\n",
            "train_loss 0.2490464\n",
            "epoch 4300   loss_test:0.26850   best_test:0.23404   sqrt_loss_test:0.51817   sqrt_best_test:0.48378\n",
            "train_loss 0.25295117\n",
            "epoch 4320   loss_test:0.24693   best_test:0.23404   sqrt_loss_test:0.49692   sqrt_best_test:0.48378\n",
            "train_loss 0.26009896\n",
            "epoch 4340   loss_test:0.24584   best_test:0.23404   sqrt_loss_test:0.49582   sqrt_best_test:0.48378\n",
            "train_loss 0.24024853\n",
            "epoch 4360   loss_test:0.26097   best_test:0.23404   sqrt_loss_test:0.51085   sqrt_best_test:0.48378\n",
            "train_loss 0.24378902\n",
            "epoch 4380   loss_test:0.24583   best_test:0.23404   sqrt_loss_test:0.49581   sqrt_best_test:0.48378\n",
            "train_loss 0.25220782\n",
            "epoch 4400   loss_test:0.26023   best_test:0.23404   sqrt_loss_test:0.51013   sqrt_best_test:0.48378\n",
            "train_loss 0.26355454\n",
            "epoch 4420   loss_test:0.24862   best_test:0.23404   sqrt_loss_test:0.49862   sqrt_best_test:0.48378\n",
            "train_loss 0.25577757\n",
            "epoch 4440   loss_test:0.25131   best_test:0.23404   sqrt_loss_test:0.50130   sqrt_best_test:0.48378\n",
            "train_loss 0.23417753\n",
            "epoch 4460   loss_test:0.25844   best_test:0.23404   sqrt_loss_test:0.50837   sqrt_best_test:0.48378\n",
            "train_loss 0.23423417\n",
            "epoch 4480   loss_test:0.29547   best_test:0.23404   sqrt_loss_test:0.54357   sqrt_best_test:0.48378\n",
            "train_loss 0.25156876\n",
            "epoch 4500   loss_test:0.25653   best_test:0.23404   sqrt_loss_test:0.50649   sqrt_best_test:0.48378\n",
            "train_loss 0.24496683\n",
            "epoch 4520   loss_test:0.25574   best_test:0.23404   sqrt_loss_test:0.50571   sqrt_best_test:0.48378\n",
            "train_loss 0.23202722\n",
            "epoch 4540   loss_test:0.24928   best_test:0.23404   sqrt_loss_test:0.49928   sqrt_best_test:0.48378\n",
            "train_loss 0.25236142\n",
            "epoch 4560   loss_test:0.25959   best_test:0.23404   sqrt_loss_test:0.50950   sqrt_best_test:0.48378\n",
            "train_loss 0.24535382\n",
            "epoch 4580   loss_test:0.23403   best_test:0.23404   sqrt_loss_test:0.48376   sqrt_best_test:0.48378\n",
            "train_loss 0.22711708\n",
            "epoch 4600   loss_test:0.25080   best_test:0.23403   sqrt_loss_test:0.50080   sqrt_best_test:0.48376\n",
            "train_loss 0.2645375\n",
            "epoch 4620   loss_test:0.25876   best_test:0.23403   sqrt_loss_test:0.50868   sqrt_best_test:0.48376\n",
            "train_loss 0.24798878\n",
            "epoch 4640   loss_test:0.24758   best_test:0.23403   sqrt_loss_test:0.49758   sqrt_best_test:0.48376\n",
            "train_loss 0.25125727\n",
            "epoch 4660   loss_test:0.26381   best_test:0.23403   sqrt_loss_test:0.51363   sqrt_best_test:0.48376\n",
            "train_loss 0.27315533\n",
            "epoch 4680   loss_test:0.24828   best_test:0.23403   sqrt_loss_test:0.49827   sqrt_best_test:0.48376\n",
            "train_loss 0.25674906\n",
            "epoch 4700   loss_test:0.25805   best_test:0.23403   sqrt_loss_test:0.50798   sqrt_best_test:0.48376\n",
            "train_loss 0.24433433\n",
            "epoch 4720   loss_test:0.23945   best_test:0.23403   sqrt_loss_test:0.48934   sqrt_best_test:0.48376\n",
            "train_loss 0.27666473\n",
            "epoch 4740   loss_test:0.27050   best_test:0.23403   sqrt_loss_test:0.52009   sqrt_best_test:0.48376\n",
            "train_loss 0.2320684\n",
            "epoch 4760   loss_test:0.23414   best_test:0.23403   sqrt_loss_test:0.48388   sqrt_best_test:0.48376\n",
            "train_loss 0.24717358\n",
            "epoch 4780   loss_test:0.25705   best_test:0.23403   sqrt_loss_test:0.50700   sqrt_best_test:0.48376\n",
            "train_loss 0.22722769\n",
            "epoch 4800   loss_test:0.24937   best_test:0.23403   sqrt_loss_test:0.49937   sqrt_best_test:0.48376\n",
            "train_loss 0.24007551\n",
            "epoch 4820   loss_test:0.24220   best_test:0.23403   sqrt_loss_test:0.49214   sqrt_best_test:0.48376\n",
            "train_loss 0.2382505\n",
            "epoch 4840   loss_test:0.25914   best_test:0.23403   sqrt_loss_test:0.50905   sqrt_best_test:0.48376\n",
            "train_loss 0.2562976\n",
            "epoch 4860   loss_test:0.24895   best_test:0.23403   sqrt_loss_test:0.49895   sqrt_best_test:0.48376\n",
            "train_loss 0.25060266\n",
            "epoch 4880   loss_test:0.27004   best_test:0.23403   sqrt_loss_test:0.51965   sqrt_best_test:0.48376\n",
            "train_loss 0.22788335\n",
            "epoch 4900   loss_test:0.24320   best_test:0.23403   sqrt_loss_test:0.49316   sqrt_best_test:0.48376\n",
            "train_loss 0.25139076\n",
            "epoch 4920   loss_test:0.24168   best_test:0.23403   sqrt_loss_test:0.49161   sqrt_best_test:0.48376\n",
            "train_loss 0.33668074\n",
            "epoch 4940   loss_test:0.26313   best_test:0.23403   sqrt_loss_test:0.51297   sqrt_best_test:0.48376\n",
            "train_loss 0.22854656\n",
            "epoch 4960   loss_test:0.24229   best_test:0.23403   sqrt_loss_test:0.49223   sqrt_best_test:0.48376\n",
            "train_loss 0.23540272\n",
            "epoch 4980   loss_test:0.24532   best_test:0.23403   sqrt_loss_test:0.49530   sqrt_best_test:0.48376\n",
            "train_loss 0.24054568\n",
            "epoch 5000   loss_test:0.26364   best_test:0.23403   sqrt_loss_test:0.51346   sqrt_best_test:0.48376\n",
            "train_loss 0.24268174\n",
            "epoch 5020   loss_test:0.25013   best_test:0.23403   sqrt_loss_test:0.50013   sqrt_best_test:0.48376\n",
            "train_loss 0.24301812\n",
            "epoch 5040   loss_test:0.25843   best_test:0.23403   sqrt_loss_test:0.50836   sqrt_best_test:0.48376\n",
            "train_loss 0.2263514\n",
            "epoch 5060   loss_test:0.25747   best_test:0.23403   sqrt_loss_test:0.50741   sqrt_best_test:0.48376\n",
            "train_loss 0.33196938\n",
            "epoch 5080   loss_test:0.23664   best_test:0.23403   sqrt_loss_test:0.48645   sqrt_best_test:0.48376\n",
            "train_loss 0.22675438\n",
            "epoch 5100   loss_test:0.25280   best_test:0.23403   sqrt_loss_test:0.50280   sqrt_best_test:0.48376\n",
            "train_loss 0.21727917\n",
            "epoch 5120   loss_test:0.24379   best_test:0.23403   sqrt_loss_test:0.49375   sqrt_best_test:0.48376\n",
            "train_loss 0.2218573\n",
            "epoch 5140   loss_test:0.25141   best_test:0.23403   sqrt_loss_test:0.50141   sqrt_best_test:0.48376\n",
            "train_loss 0.24567175\n",
            "epoch 5160   loss_test:0.24436   best_test:0.23403   sqrt_loss_test:0.49432   sqrt_best_test:0.48376\n",
            "train_loss 0.24534468\n",
            "epoch 5180   loss_test:0.25904   best_test:0.23403   sqrt_loss_test:0.50896   sqrt_best_test:0.48376\n",
            "train_loss 0.21520117\n",
            "epoch 5200   loss_test:0.24721   best_test:0.23403   sqrt_loss_test:0.49721   sqrt_best_test:0.48376\n",
            "train_loss 0.21758482\n",
            "epoch 5220   loss_test:0.22550   best_test:0.23403   sqrt_loss_test:0.47487   sqrt_best_test:0.48376\n",
            "train_loss 0.24461928\n",
            "epoch 5240   loss_test:0.23470   best_test:0.22550   sqrt_loss_test:0.48446   sqrt_best_test:0.47487\n",
            "train_loss 0.24921386\n",
            "epoch 5260   loss_test:0.25910   best_test:0.22550   sqrt_loss_test:0.50902   sqrt_best_test:0.47487\n",
            "train_loss 0.24661699\n",
            "epoch 5280   loss_test:0.25133   best_test:0.22550   sqrt_loss_test:0.50133   sqrt_best_test:0.47487\n",
            "train_loss 0.22556934\n",
            "epoch 5300   loss_test:0.23322   best_test:0.22550   sqrt_loss_test:0.48293   sqrt_best_test:0.47487\n",
            "train_loss 0.23297614\n",
            "epoch 5320   loss_test:0.26000   best_test:0.22550   sqrt_loss_test:0.50990   sqrt_best_test:0.47487\n",
            "train_loss 0.23675069\n",
            "epoch 5340   loss_test:0.24857   best_test:0.22550   sqrt_loss_test:0.49857   sqrt_best_test:0.47487\n",
            "train_loss 0.22542071\n",
            "epoch 5360   loss_test:0.24607   best_test:0.22550   sqrt_loss_test:0.49606   sqrt_best_test:0.47487\n",
            "train_loss 0.23732875\n",
            "epoch 5380   loss_test:0.23498   best_test:0.22550   sqrt_loss_test:0.48475   sqrt_best_test:0.47487\n",
            "train_loss 0.23677428\n",
            "epoch 5400   loss_test:0.22745   best_test:0.22550   sqrt_loss_test:0.47691   sqrt_best_test:0.47487\n",
            "train_loss 0.24345347\n",
            "epoch 5420   loss_test:0.26645   best_test:0.22550   sqrt_loss_test:0.51619   sqrt_best_test:0.47487\n",
            "train_loss 0.24541774\n",
            "epoch 5440   loss_test:0.23832   best_test:0.22550   sqrt_loss_test:0.48818   sqrt_best_test:0.47487\n",
            "train_loss 0.22238846\n",
            "epoch 5460   loss_test:0.27105   best_test:0.22550   sqrt_loss_test:0.52062   sqrt_best_test:0.47487\n",
            "train_loss 0.22241357\n",
            "epoch 5480   loss_test:0.25808   best_test:0.22550   sqrt_loss_test:0.50802   sqrt_best_test:0.47487\n",
            "train_loss 0.2239253\n",
            "epoch 5500   loss_test:0.25361   best_test:0.22550   sqrt_loss_test:0.50359   sqrt_best_test:0.47487\n",
            "train_loss 0.25056952\n",
            "epoch 5520   loss_test:0.24878   best_test:0.22550   sqrt_loss_test:0.49877   sqrt_best_test:0.47487\n",
            "train_loss 0.22649115\n",
            "epoch 5540   loss_test:0.23106   best_test:0.22550   sqrt_loss_test:0.48068   sqrt_best_test:0.47487\n",
            "train_loss 0.22079235\n",
            "epoch 5560   loss_test:0.25443   best_test:0.22550   sqrt_loss_test:0.50441   sqrt_best_test:0.47487\n",
            "train_loss 0.21395777\n",
            "epoch 5580   loss_test:0.23986   best_test:0.22550   sqrt_loss_test:0.48975   sqrt_best_test:0.47487\n",
            "train_loss 0.237228\n",
            "epoch 5600   loss_test:0.24484   best_test:0.22550   sqrt_loss_test:0.49481   sqrt_best_test:0.47487\n",
            "train_loss 0.232503\n",
            "epoch 5620   loss_test:0.25006   best_test:0.22550   sqrt_loss_test:0.50006   sqrt_best_test:0.47487\n",
            "train_loss 0.21149212\n",
            "epoch 5640   loss_test:0.23964   best_test:0.22550   sqrt_loss_test:0.48953   sqrt_best_test:0.47487\n",
            "train_loss 0.22036615\n",
            "epoch 5660   loss_test:0.24296   best_test:0.22550   sqrt_loss_test:0.49291   sqrt_best_test:0.47487\n",
            "train_loss 0.23749171\n",
            "epoch 5680   loss_test:0.23889   best_test:0.22550   sqrt_loss_test:0.48876   sqrt_best_test:0.47487\n",
            "train_loss 0.30083457\n",
            "epoch 5700   loss_test:0.24175   best_test:0.22550   sqrt_loss_test:0.49169   sqrt_best_test:0.47487\n",
            "train_loss 0.23361881\n",
            "epoch 5720   loss_test:0.22767   best_test:0.22550   sqrt_loss_test:0.47715   sqrt_best_test:0.47487\n",
            "train_loss 0.22159922\n",
            "epoch 5740   loss_test:0.24302   best_test:0.22550   sqrt_loss_test:0.49297   sqrt_best_test:0.47487\n",
            "train_loss 0.21253493\n",
            "epoch 5760   loss_test:0.23460   best_test:0.22550   sqrt_loss_test:0.48436   sqrt_best_test:0.47487\n",
            "train_loss 0.22397673\n",
            "epoch 5780   loss_test:0.25840   best_test:0.22550   sqrt_loss_test:0.50833   sqrt_best_test:0.47487\n",
            "train_loss 0.26064134\n",
            "epoch 5800   loss_test:0.23822   best_test:0.22550   sqrt_loss_test:0.48808   sqrt_best_test:0.47487\n",
            "train_loss 0.22554019\n",
            "epoch 5820   loss_test:0.24319   best_test:0.22550   sqrt_loss_test:0.49314   sqrt_best_test:0.47487\n",
            "train_loss 0.22455364\n",
            "epoch 5840   loss_test:0.25124   best_test:0.22550   sqrt_loss_test:0.50124   sqrt_best_test:0.47487\n",
            "train_loss 0.2160753\n",
            "epoch 5860   loss_test:0.25956   best_test:0.22550   sqrt_loss_test:0.50947   sqrt_best_test:0.47487\n",
            "train_loss 0.23697871\n",
            "epoch 5880   loss_test:0.24140   best_test:0.22550   sqrt_loss_test:0.49132   sqrt_best_test:0.47487\n",
            "train_loss 0.23043352\n",
            "epoch 5900   loss_test:0.24577   best_test:0.22550   sqrt_loss_test:0.49576   sqrt_best_test:0.47487\n",
            "train_loss 0.21971026\n",
            "epoch 5920   loss_test:0.24671   best_test:0.22550   sqrt_loss_test:0.49670   sqrt_best_test:0.47487\n",
            "train_loss 0.20296207\n",
            "epoch 5940   loss_test:0.24539   best_test:0.22550   sqrt_loss_test:0.49537   sqrt_best_test:0.47487\n",
            "train_loss 0.23253596\n",
            "epoch 5960   loss_test:0.22762   best_test:0.22550   sqrt_loss_test:0.47709   sqrt_best_test:0.47487\n",
            "train_loss 0.22683166\n",
            "epoch 5980   loss_test:0.24603   best_test:0.22550   sqrt_loss_test:0.49601   sqrt_best_test:0.47487\n",
            "train_loss 0.23692328\n",
            "epoch 6000   loss_test:0.24649   best_test:0.22550   sqrt_loss_test:0.49648   sqrt_best_test:0.47487\n",
            "train_loss 0.23332322\n",
            "epoch 6020   loss_test:0.22728   best_test:0.22550   sqrt_loss_test:0.47674   sqrt_best_test:0.47487\n",
            "train_loss 0.23287454\n",
            "epoch 6040   loss_test:0.24967   best_test:0.22550   sqrt_loss_test:0.49967   sqrt_best_test:0.47487\n",
            "train_loss 0.21930654\n",
            "epoch 6060   loss_test:0.24537   best_test:0.22550   sqrt_loss_test:0.49534   sqrt_best_test:0.47487\n",
            "train_loss 0.23486295\n",
            "epoch 6080   loss_test:0.24460   best_test:0.22550   sqrt_loss_test:0.49457   sqrt_best_test:0.47487\n",
            "train_loss 0.23844814\n",
            "epoch 6100   loss_test:0.23720   best_test:0.22550   sqrt_loss_test:0.48703   sqrt_best_test:0.47487\n",
            "train_loss 0.27322856\n",
            "epoch 6120   loss_test:0.25870   best_test:0.22550   sqrt_loss_test:0.50862   sqrt_best_test:0.47487\n",
            "train_loss 0.24031988\n",
            "epoch 6140   loss_test:0.24513   best_test:0.22550   sqrt_loss_test:0.49511   sqrt_best_test:0.47487\n",
            "train_loss 0.22103967\n",
            "epoch 6160   loss_test:0.23156   best_test:0.22550   sqrt_loss_test:0.48121   sqrt_best_test:0.47487\n",
            "train_loss 0.23754156\n",
            "epoch 6180   loss_test:0.24007   best_test:0.22550   sqrt_loss_test:0.48997   sqrt_best_test:0.47487\n",
            "train_loss 0.23654874\n",
            "epoch 6200   loss_test:0.22284   best_test:0.22550   sqrt_loss_test:0.47206   sqrt_best_test:0.47487\n",
            "train_loss 0.22750436\n",
            "epoch 6220   loss_test:0.24180   best_test:0.22284   sqrt_loss_test:0.49173   sqrt_best_test:0.47206\n",
            "train_loss 0.23401317\n",
            "epoch 6240   loss_test:0.23290   best_test:0.22284   sqrt_loss_test:0.48260   sqrt_best_test:0.47206\n",
            "train_loss 0.22764194\n",
            "epoch 6260   loss_test:0.26516   best_test:0.22284   sqrt_loss_test:0.51494   sqrt_best_test:0.47206\n",
            "train_loss 0.21826082\n",
            "epoch 6280   loss_test:0.23318   best_test:0.22284   sqrt_loss_test:0.48289   sqrt_best_test:0.47206\n",
            "train_loss 0.2187415\n",
            "epoch 6300   loss_test:0.23798   best_test:0.22284   sqrt_loss_test:0.48783   sqrt_best_test:0.47206\n",
            "train_loss 0.21277003\n",
            "epoch 6320   loss_test:0.32289   best_test:0.22284   sqrt_loss_test:0.56823   sqrt_best_test:0.47206\n",
            "train_loss 0.22616786\n",
            "epoch 6340   loss_test:0.24463   best_test:0.22284   sqrt_loss_test:0.49460   sqrt_best_test:0.47206\n",
            "train_loss 0.20759805\n",
            "epoch 6360   loss_test:0.23020   best_test:0.22284   sqrt_loss_test:0.47979   sqrt_best_test:0.47206\n",
            "train_loss 0.22113064\n",
            "epoch 6380   loss_test:0.23696   best_test:0.22284   sqrt_loss_test:0.48679   sqrt_best_test:0.47206\n",
            "train_loss 0.22771733\n",
            "epoch 6400   loss_test:0.22311   best_test:0.22284   sqrt_loss_test:0.47234   sqrt_best_test:0.47206\n",
            "train_loss 0.21528123\n",
            "epoch 6420   loss_test:0.24797   best_test:0.22284   sqrt_loss_test:0.49797   sqrt_best_test:0.47206\n",
            "train_loss 0.23286971\n",
            "epoch 6440   loss_test:0.21769   best_test:0.22284   sqrt_loss_test:0.46657   sqrt_best_test:0.47206\n",
            "train_loss 0.21241418\n",
            "epoch 6460   loss_test:0.24147   best_test:0.21769   sqrt_loss_test:0.49140   sqrt_best_test:0.46657\n",
            "train_loss 0.21730402\n",
            "epoch 6480   loss_test:0.23167   best_test:0.21769   sqrt_loss_test:0.48132   sqrt_best_test:0.46657\n",
            "train_loss 0.2239587\n",
            "epoch 6500   loss_test:0.24358   best_test:0.21769   sqrt_loss_test:0.49353   sqrt_best_test:0.46657\n",
            "train_loss 0.24560663\n",
            "epoch 6520   loss_test:0.23639   best_test:0.21769   sqrt_loss_test:0.48619   sqrt_best_test:0.46657\n",
            "train_loss 0.22891104\n",
            "epoch 6540   loss_test:0.23774   best_test:0.21769   sqrt_loss_test:0.48758   sqrt_best_test:0.46657\n",
            "train_loss 0.23393056\n",
            "epoch 6560   loss_test:0.23038   best_test:0.21769   sqrt_loss_test:0.47998   sqrt_best_test:0.46657\n",
            "train_loss 0.21793962\n",
            "epoch 6580   loss_test:0.24070   best_test:0.21769   sqrt_loss_test:0.49061   sqrt_best_test:0.46657\n",
            "train_loss 0.21605591\n",
            "epoch 6600   loss_test:0.24108   best_test:0.21769   sqrt_loss_test:0.49100   sqrt_best_test:0.46657\n",
            "train_loss 0.23068748\n",
            "epoch 6620   loss_test:0.25175   best_test:0.21769   sqrt_loss_test:0.50175   sqrt_best_test:0.46657\n",
            "train_loss 0.22678255\n",
            "epoch 6640   loss_test:0.26377   best_test:0.21769   sqrt_loss_test:0.51358   sqrt_best_test:0.46657\n",
            "train_loss 0.24080776\n",
            "epoch 6660   loss_test:0.23902   best_test:0.21769   sqrt_loss_test:0.48889   sqrt_best_test:0.46657\n",
            "train_loss 0.22183111\n",
            "epoch 6680   loss_test:0.23273   best_test:0.21769   sqrt_loss_test:0.48242   sqrt_best_test:0.46657\n",
            "train_loss 0.2573265\n",
            "epoch 6700   loss_test:0.22973   best_test:0.21769   sqrt_loss_test:0.47931   sqrt_best_test:0.46657\n",
            "train_loss 0.22020432\n",
            "epoch 6720   loss_test:0.23440   best_test:0.21769   sqrt_loss_test:0.48415   sqrt_best_test:0.46657\n",
            "train_loss 0.2645969\n",
            "epoch 6740   loss_test:0.28979   best_test:0.21769   sqrt_loss_test:0.53832   sqrt_best_test:0.46657\n",
            "train_loss 0.21213701\n",
            "epoch 6760   loss_test:0.23039   best_test:0.21769   sqrt_loss_test:0.47999   sqrt_best_test:0.46657\n",
            "train_loss 0.20742562\n",
            "epoch 6780   loss_test:0.24990   best_test:0.21769   sqrt_loss_test:0.49990   sqrt_best_test:0.46657\n",
            "train_loss 0.2193667\n",
            "epoch 6800   loss_test:0.25570   best_test:0.21769   sqrt_loss_test:0.50567   sqrt_best_test:0.46657\n",
            "train_loss 0.2201611\n",
            "epoch 6820   loss_test:0.24468   best_test:0.21769   sqrt_loss_test:0.49465   sqrt_best_test:0.46657\n",
            "train_loss 0.21023183\n",
            "epoch 6840   loss_test:0.22811   best_test:0.21769   sqrt_loss_test:0.47761   sqrt_best_test:0.46657\n",
            "train_loss 0.20152794\n",
            "epoch 6860   loss_test:0.23429   best_test:0.21769   sqrt_loss_test:0.48404   sqrt_best_test:0.46657\n",
            "train_loss 0.21076512\n",
            "epoch 6880   loss_test:0.23450   best_test:0.21769   sqrt_loss_test:0.48426   sqrt_best_test:0.46657\n",
            "train_loss 0.21972965\n",
            "epoch 6900   loss_test:0.24698   best_test:0.21769   sqrt_loss_test:0.49698   sqrt_best_test:0.46657\n",
            "train_loss 0.23864396\n",
            "epoch 6920   loss_test:0.25003   best_test:0.21769   sqrt_loss_test:0.50003   sqrt_best_test:0.46657\n",
            "train_loss 0.21102357\n",
            "epoch 6940   loss_test:0.23337   best_test:0.21769   sqrt_loss_test:0.48309   sqrt_best_test:0.46657\n",
            "train_loss 0.245086\n",
            "epoch 6960   loss_test:0.22872   best_test:0.21769   sqrt_loss_test:0.47824   sqrt_best_test:0.46657\n",
            "train_loss 0.25145024\n",
            "epoch 6980   loss_test:0.23812   best_test:0.21769   sqrt_loss_test:0.48797   sqrt_best_test:0.46657\n",
            "train_loss 0.22042339\n",
            "epoch 7000   loss_test:0.22994   best_test:0.21769   sqrt_loss_test:0.47952   sqrt_best_test:0.46657\n",
            "train_loss 0.25346974\n",
            "epoch 7020   loss_test:0.23964   best_test:0.21769   sqrt_loss_test:0.48953   sqrt_best_test:0.46657\n",
            "train_loss 0.21287534\n",
            "epoch 7040   loss_test:0.22678   best_test:0.21769   sqrt_loss_test:0.47621   sqrt_best_test:0.46657\n",
            "train_loss 0.2114006\n",
            "epoch 7060   loss_test:0.22811   best_test:0.21769   sqrt_loss_test:0.47761   sqrt_best_test:0.46657\n",
            "train_loss 0.22162156\n",
            "epoch 7080   loss_test:0.23182   best_test:0.21769   sqrt_loss_test:0.48147   sqrt_best_test:0.46657\n",
            "train_loss 0.20911129\n",
            "epoch 7100   loss_test:0.23692   best_test:0.21769   sqrt_loss_test:0.48675   sqrt_best_test:0.46657\n",
            "train_loss 0.21766873\n",
            "epoch 7120   loss_test:0.22926   best_test:0.21769   sqrt_loss_test:0.47881   sqrt_best_test:0.46657\n",
            "train_loss 0.2174644\n",
            "epoch 7140   loss_test:0.21949   best_test:0.21769   sqrt_loss_test:0.46850   sqrt_best_test:0.46657\n",
            "train_loss 0.2081691\n",
            "epoch 7160   loss_test:0.24264   best_test:0.21769   sqrt_loss_test:0.49259   sqrt_best_test:0.46657\n",
            "train_loss 0.21772271\n",
            "epoch 7180   loss_test:0.23409   best_test:0.21769   sqrt_loss_test:0.48382   sqrt_best_test:0.46657\n",
            "train_loss 0.21068177\n",
            "epoch 7200   loss_test:0.23517   best_test:0.21769   sqrt_loss_test:0.48494   sqrt_best_test:0.46657\n",
            "train_loss 0.22936317\n",
            "epoch 7220   loss_test:0.23351   best_test:0.21769   sqrt_loss_test:0.48322   sqrt_best_test:0.46657\n",
            "train_loss 0.22839569\n",
            "epoch 7240   loss_test:0.26626   best_test:0.21769   sqrt_loss_test:0.51600   sqrt_best_test:0.46657\n",
            "train_loss 0.22007383\n",
            "epoch 7260   loss_test:0.23818   best_test:0.21769   sqrt_loss_test:0.48804   sqrt_best_test:0.46657\n",
            "train_loss 0.2078017\n",
            "epoch 7280   loss_test:0.22925   best_test:0.21769   sqrt_loss_test:0.47880   sqrt_best_test:0.46657\n",
            "train_loss 0.22447623\n",
            "epoch 7300   loss_test:0.23695   best_test:0.21769   sqrt_loss_test:0.48677   sqrt_best_test:0.46657\n",
            "train_loss 0.22572112\n",
            "epoch 7320   loss_test:0.25040   best_test:0.21769   sqrt_loss_test:0.50040   sqrt_best_test:0.46657\n",
            "train_loss 0.20723513\n",
            "epoch 7340   loss_test:0.23781   best_test:0.21769   sqrt_loss_test:0.48766   sqrt_best_test:0.46657\n",
            "train_loss 0.22387189\n",
            "epoch 7360   loss_test:0.22561   best_test:0.21769   sqrt_loss_test:0.47498   sqrt_best_test:0.46657\n",
            "train_loss 0.22289547\n",
            "epoch 7380   loss_test:0.21525   best_test:0.21769   sqrt_loss_test:0.46395   sqrt_best_test:0.46657\n",
            "train_loss 0.21743566\n",
            "epoch 7400   loss_test:0.24626   best_test:0.21525   sqrt_loss_test:0.49624   sqrt_best_test:0.46395\n",
            "train_loss 0.22353159\n",
            "epoch 7420   loss_test:0.24796   best_test:0.21525   sqrt_loss_test:0.49795   sqrt_best_test:0.46395\n",
            "train_loss 0.19898458\n",
            "epoch 7440   loss_test:0.23057   best_test:0.21525   sqrt_loss_test:0.48017   sqrt_best_test:0.46395\n",
            "train_loss 0.22964713\n",
            "epoch 7460   loss_test:0.23537   best_test:0.21525   sqrt_loss_test:0.48515   sqrt_best_test:0.46395\n",
            "train_loss 0.22773755\n",
            "epoch 7480   loss_test:0.23407   best_test:0.21525   sqrt_loss_test:0.48381   sqrt_best_test:0.46395\n",
            "train_loss 0.19402124\n",
            "epoch 7500   loss_test:0.22029   best_test:0.21525   sqrt_loss_test:0.46935   sqrt_best_test:0.46395\n",
            "train_loss 0.22454305\n",
            "epoch 7520   loss_test:0.22253   best_test:0.21525   sqrt_loss_test:0.47173   sqrt_best_test:0.46395\n",
            "train_loss 0.2131612\n",
            "epoch 7540   loss_test:0.22333   best_test:0.21525   sqrt_loss_test:0.47258   sqrt_best_test:0.46395\n",
            "train_loss 0.21636206\n",
            "epoch 7560   loss_test:0.24904   best_test:0.21525   sqrt_loss_test:0.49904   sqrt_best_test:0.46395\n",
            "train_loss 0.22456913\n",
            "epoch 7580   loss_test:0.24063   best_test:0.21525   sqrt_loss_test:0.49054   sqrt_best_test:0.46395\n",
            "train_loss 0.22466084\n",
            "epoch 7600   loss_test:0.21731   best_test:0.21525   sqrt_loss_test:0.46616   sqrt_best_test:0.46395\n",
            "train_loss 0.23393661\n",
            "epoch 7620   loss_test:0.24110   best_test:0.21525   sqrt_loss_test:0.49102   sqrt_best_test:0.46395\n",
            "train_loss 0.19744898\n",
            "epoch 7640   loss_test:0.22347   best_test:0.21525   sqrt_loss_test:0.47272   sqrt_best_test:0.46395\n",
            "train_loss 0.22698954\n",
            "epoch 7660   loss_test:0.22272   best_test:0.21525   sqrt_loss_test:0.47193   sqrt_best_test:0.46395\n",
            "train_loss 0.21814224\n",
            "epoch 7680   loss_test:0.23767   best_test:0.21525   sqrt_loss_test:0.48751   sqrt_best_test:0.46395\n",
            "train_loss 0.22821155\n",
            "epoch 7700   loss_test:0.24929   best_test:0.21525   sqrt_loss_test:0.49929   sqrt_best_test:0.46395\n",
            "train_loss 0.21269295\n",
            "epoch 7720   loss_test:0.24493   best_test:0.21525   sqrt_loss_test:0.49491   sqrt_best_test:0.46395\n",
            "train_loss 0.21429034\n",
            "epoch 7740   loss_test:0.23188   best_test:0.21525   sqrt_loss_test:0.48154   sqrt_best_test:0.46395\n",
            "train_loss 0.20998889\n",
            "epoch 7760   loss_test:0.23141   best_test:0.21525   sqrt_loss_test:0.48105   sqrt_best_test:0.46395\n",
            "train_loss 0.21827067\n",
            "epoch 7780   loss_test:0.23649   best_test:0.21525   sqrt_loss_test:0.48630   sqrt_best_test:0.46395\n",
            "train_loss 0.22377934\n",
            "epoch 7800   loss_test:0.23548   best_test:0.21525   sqrt_loss_test:0.48527   sqrt_best_test:0.46395\n",
            "train_loss 0.21371287\n",
            "epoch 7820   loss_test:0.22218   best_test:0.21525   sqrt_loss_test:0.47136   sqrt_best_test:0.46395\n",
            "train_loss 0.22294031\n",
            "epoch 7840   loss_test:0.22651   best_test:0.21525   sqrt_loss_test:0.47593   sqrt_best_test:0.46395\n",
            "train_loss 0.21754774\n",
            "epoch 7860   loss_test:0.23526   best_test:0.21525   sqrt_loss_test:0.48504   sqrt_best_test:0.46395\n",
            "train_loss 0.23090315\n",
            "epoch 7880   loss_test:0.24529   best_test:0.21525   sqrt_loss_test:0.49526   sqrt_best_test:0.46395\n",
            "train_loss 0.23340882\n",
            "epoch 7900   loss_test:0.24773   best_test:0.21525   sqrt_loss_test:0.49772   sqrt_best_test:0.46395\n",
            "train_loss 0.24126585\n",
            "epoch 7920   loss_test:0.25440   best_test:0.21525   sqrt_loss_test:0.50438   sqrt_best_test:0.46395\n",
            "train_loss 0.21911927\n",
            "epoch 7940   loss_test:0.22535   best_test:0.21525   sqrt_loss_test:0.47471   sqrt_best_test:0.46395\n",
            "train_loss 0.20409207\n",
            "epoch 7960   loss_test:0.22430   best_test:0.21525   sqrt_loss_test:0.47361   sqrt_best_test:0.46395\n",
            "train_loss 0.22059129\n",
            "epoch 7980   loss_test:0.21164   best_test:0.21525   sqrt_loss_test:0.46005   sqrt_best_test:0.46395\n",
            "train_loss 0.22436397\n",
            "epoch 8000   loss_test:0.22733   best_test:0.21164   sqrt_loss_test:0.47679   sqrt_best_test:0.46005\n",
            "train_loss 0.21241032\n",
            "epoch 8020   loss_test:0.20606   best_test:0.21164   sqrt_loss_test:0.45394   sqrt_best_test:0.46005\n",
            "train_loss 0.20435913\n",
            "epoch 8040   loss_test:0.24063   best_test:0.20606   sqrt_loss_test:0.49054   sqrt_best_test:0.45394\n",
            "train_loss 0.20841193\n",
            "epoch 8060   loss_test:0.22304   best_test:0.20606   sqrt_loss_test:0.47227   sqrt_best_test:0.45394\n",
            "train_loss 0.2216989\n",
            "epoch 8080   loss_test:0.23669   best_test:0.20606   sqrt_loss_test:0.48650   sqrt_best_test:0.45394\n",
            "train_loss 0.21116604\n",
            "epoch 8100   loss_test:0.23094   best_test:0.20606   sqrt_loss_test:0.48057   sqrt_best_test:0.45394\n",
            "train_loss 0.20703943\n",
            "epoch 8120   loss_test:0.21322   best_test:0.20606   sqrt_loss_test:0.46176   sqrt_best_test:0.45394\n",
            "train_loss 0.21962398\n",
            "epoch 8140   loss_test:0.22535   best_test:0.20606   sqrt_loss_test:0.47472   sqrt_best_test:0.45394\n",
            "train_loss 0.22272977\n",
            "epoch 8160   loss_test:0.24943   best_test:0.20606   sqrt_loss_test:0.49943   sqrt_best_test:0.45394\n",
            "train_loss 0.21199442\n",
            "epoch 8180   loss_test:0.24781   best_test:0.20606   sqrt_loss_test:0.49780   sqrt_best_test:0.45394\n",
            "train_loss 0.20482539\n",
            "epoch 8200   loss_test:0.22758   best_test:0.20606   sqrt_loss_test:0.47705   sqrt_best_test:0.45394\n",
            "train_loss 0.20613416\n",
            "epoch 8220   loss_test:0.22783   best_test:0.20606   sqrt_loss_test:0.47732   sqrt_best_test:0.45394\n",
            "train_loss 0.20527689\n",
            "epoch 8240   loss_test:0.23064   best_test:0.20606   sqrt_loss_test:0.48025   sqrt_best_test:0.45394\n",
            "train_loss 0.23387598\n",
            "epoch 8260   loss_test:0.24247   best_test:0.20606   sqrt_loss_test:0.49241   sqrt_best_test:0.45394\n",
            "train_loss 0.22128603\n",
            "epoch 8280   loss_test:0.21248   best_test:0.20606   sqrt_loss_test:0.46095   sqrt_best_test:0.45394\n",
            "train_loss 0.21892177\n",
            "epoch 8300   loss_test:0.22920   best_test:0.20606   sqrt_loss_test:0.47875   sqrt_best_test:0.45394\n",
            "train_loss 0.21870297\n",
            "epoch 8320   loss_test:0.22975   best_test:0.20606   sqrt_loss_test:0.47932   sqrt_best_test:0.45394\n",
            "train_loss 0.20973268\n",
            "epoch 8340   loss_test:0.24773   best_test:0.20606   sqrt_loss_test:0.49773   sqrt_best_test:0.45394\n",
            "train_loss 0.2113601\n",
            "epoch 8360   loss_test:0.20844   best_test:0.20606   sqrt_loss_test:0.45656   sqrt_best_test:0.45394\n",
            "train_loss 0.19443305\n",
            "epoch 8380   loss_test:0.22069   best_test:0.20606   sqrt_loss_test:0.46978   sqrt_best_test:0.45394\n",
            "train_loss 0.23258655\n",
            "epoch 8400   loss_test:0.22645   best_test:0.20606   sqrt_loss_test:0.47586   sqrt_best_test:0.45394\n",
            "train_loss 0.20841974\n",
            "epoch 8420   loss_test:0.21416   best_test:0.20606   sqrt_loss_test:0.46277   sqrt_best_test:0.45394\n",
            "train_loss 0.20141476\n",
            "epoch 8440   loss_test:0.22935   best_test:0.20606   sqrt_loss_test:0.47890   sqrt_best_test:0.45394\n",
            "train_loss 0.19808425\n",
            "epoch 8460   loss_test:0.23610   best_test:0.20606   sqrt_loss_test:0.48590   sqrt_best_test:0.45394\n",
            "train_loss 0.21689215\n",
            "epoch 8480   loss_test:0.22561   best_test:0.20606   sqrt_loss_test:0.47498   sqrt_best_test:0.45394\n",
            "train_loss 0.21309426\n",
            "epoch 8500   loss_test:0.21548   best_test:0.20606   sqrt_loss_test:0.46420   sqrt_best_test:0.45394\n",
            "train_loss 0.21239144\n",
            "epoch 8520   loss_test:0.23057   best_test:0.20606   sqrt_loss_test:0.48018   sqrt_best_test:0.45394\n",
            "train_loss 0.19996852\n",
            "epoch 8540   loss_test:0.21116   best_test:0.20606   sqrt_loss_test:0.45952   sqrt_best_test:0.45394\n",
            "train_loss 0.19768488\n",
            "epoch 8560   loss_test:0.22991   best_test:0.20606   sqrt_loss_test:0.47949   sqrt_best_test:0.45394\n",
            "train_loss 0.21102493\n",
            "epoch 8580   loss_test:0.23744   best_test:0.20606   sqrt_loss_test:0.48728   sqrt_best_test:0.45394\n",
            "train_loss 0.23190987\n",
            "epoch 8600   loss_test:0.21738   best_test:0.20606   sqrt_loss_test:0.46624   sqrt_best_test:0.45394\n",
            "train_loss 0.22711521\n",
            "epoch 8620   loss_test:0.21030   best_test:0.20606   sqrt_loss_test:0.45859   sqrt_best_test:0.45394\n",
            "train_loss 0.20862415\n",
            "epoch 8640   loss_test:0.22055   best_test:0.20606   sqrt_loss_test:0.46963   sqrt_best_test:0.45394\n",
            "train_loss 0.19460446\n",
            "epoch 8660   loss_test:0.24014   best_test:0.20606   sqrt_loss_test:0.49004   sqrt_best_test:0.45394\n",
            "train_loss 0.20016369\n",
            "epoch 8680   loss_test:0.23827   best_test:0.20606   sqrt_loss_test:0.48813   sqrt_best_test:0.45394\n",
            "train_loss 0.21201238\n",
            "epoch 8700   loss_test:0.23629   best_test:0.20606   sqrt_loss_test:0.48610   sqrt_best_test:0.45394\n",
            "train_loss 0.20163935\n",
            "epoch 8720   loss_test:0.23452   best_test:0.20606   sqrt_loss_test:0.48427   sqrt_best_test:0.45394\n",
            "train_loss 0.22884083\n",
            "epoch 8740   loss_test:0.23688   best_test:0.20606   sqrt_loss_test:0.48671   sqrt_best_test:0.45394\n",
            "train_loss 0.21911505\n",
            "epoch 8760   loss_test:0.22126   best_test:0.20606   sqrt_loss_test:0.47038   sqrt_best_test:0.45394\n",
            "train_loss 0.20543568\n",
            "epoch 8780   loss_test:0.24198   best_test:0.20606   sqrt_loss_test:0.49191   sqrt_best_test:0.45394\n",
            "train_loss 0.18809885\n",
            "epoch 8800   loss_test:0.23048   best_test:0.20606   sqrt_loss_test:0.48008   sqrt_best_test:0.45394\n",
            "train_loss 0.2112613\n",
            "epoch 8820   loss_test:0.22152   best_test:0.20606   sqrt_loss_test:0.47065   sqrt_best_test:0.45394\n",
            "train_loss 0.22179116\n",
            "epoch 8840   loss_test:0.23161   best_test:0.20606   sqrt_loss_test:0.48126   sqrt_best_test:0.45394\n",
            "train_loss 0.21283162\n",
            "epoch 8860   loss_test:0.22653   best_test:0.20606   sqrt_loss_test:0.47595   sqrt_best_test:0.45394\n",
            "train_loss 0.20855533\n",
            "epoch 8880   loss_test:0.23933   best_test:0.20606   sqrt_loss_test:0.48922   sqrt_best_test:0.45394\n",
            "train_loss 0.20913297\n",
            "epoch 8900   loss_test:0.22485   best_test:0.20606   sqrt_loss_test:0.47419   sqrt_best_test:0.45394\n",
            "train_loss 0.2008804\n",
            "epoch 8920   loss_test:0.22274   best_test:0.20606   sqrt_loss_test:0.47195   sqrt_best_test:0.45394\n",
            "train_loss 0.20300439\n",
            "epoch 8940   loss_test:0.23198   best_test:0.20606   sqrt_loss_test:0.48164   sqrt_best_test:0.45394\n",
            "train_loss 0.2182447\n",
            "epoch 8960   loss_test:0.26048   best_test:0.20606   sqrt_loss_test:0.51037   sqrt_best_test:0.45394\n",
            "train_loss 0.19126245\n",
            "epoch 8980   loss_test:0.23429   best_test:0.20606   sqrt_loss_test:0.48404   sqrt_best_test:0.45394\n",
            "train_loss 0.20607288\n",
            "epoch 9000   loss_test:0.22629   best_test:0.20606   sqrt_loss_test:0.47570   sqrt_best_test:0.45394\n",
            "train_loss 0.22225067\n",
            "epoch 9020   loss_test:0.25651   best_test:0.20606   sqrt_loss_test:0.50647   sqrt_best_test:0.45394\n",
            "train_loss 0.21265447\n",
            "epoch 9040   loss_test:0.22836   best_test:0.20606   sqrt_loss_test:0.47787   sqrt_best_test:0.45394\n",
            "train_loss 0.20169462\n",
            "epoch 9060   loss_test:0.24207   best_test:0.20606   sqrt_loss_test:0.49201   sqrt_best_test:0.45394\n",
            "train_loss 0.2028982\n",
            "epoch 9080   loss_test:0.21378   best_test:0.20606   sqrt_loss_test:0.46236   sqrt_best_test:0.45394\n",
            "train_loss 0.20681472\n",
            "epoch 9100   loss_test:0.22632   best_test:0.20606   sqrt_loss_test:0.47573   sqrt_best_test:0.45394\n",
            "train_loss 0.20786247\n",
            "epoch 9120   loss_test:0.23297   best_test:0.20606   sqrt_loss_test:0.48267   sqrt_best_test:0.45394\n",
            "train_loss 0.21119325\n",
            "epoch 9140   loss_test:0.22501   best_test:0.20606   sqrt_loss_test:0.47435   sqrt_best_test:0.45394\n",
            "train_loss 0.20832537\n",
            "epoch 9160   loss_test:0.20990   best_test:0.20606   sqrt_loss_test:0.45815   sqrt_best_test:0.45394\n",
            "train_loss 0.20272468\n",
            "epoch 9180   loss_test:0.22693   best_test:0.20606   sqrt_loss_test:0.47637   sqrt_best_test:0.45394\n",
            "train_loss 0.2255224\n",
            "epoch 9200   loss_test:0.24308   best_test:0.20606   sqrt_loss_test:0.49303   sqrt_best_test:0.45394\n",
            "train_loss 0.20515516\n",
            "epoch 9220   loss_test:0.22495   best_test:0.20606   sqrt_loss_test:0.47429   sqrt_best_test:0.45394\n",
            "train_loss 0.20379923\n",
            "epoch 9240   loss_test:0.22933   best_test:0.20606   sqrt_loss_test:0.47889   sqrt_best_test:0.45394\n",
            "train_loss 0.20580448\n",
            "epoch 9260   loss_test:0.21876   best_test:0.20606   sqrt_loss_test:0.46772   sqrt_best_test:0.45394\n",
            "train_loss 0.18471327\n",
            "epoch 9280   loss_test:0.23726   best_test:0.20606   sqrt_loss_test:0.48709   sqrt_best_test:0.45394\n",
            "train_loss 0.2202746\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5ef11138ba69>\u001b[0m in \u001b[0;36m<cell line: 372>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    402\u001b[0m                                    \u001b[0mchannel_bs_irs_user\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchannel_bs_irs_user_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                    channel_bs_user:Train_channel_bs_user[choice,:]}\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0mbatch_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    970\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    971\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1373\u001b[0m                            run_metadata)\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1363\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1454\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1455\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1456\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                                             run_metadata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import tensorflow.compat.v1 as tf\n",
        "import time\n",
        "\n",
        "\n",
        "def generate_user_location(number_samples, num_users,location_user):\n",
        "    x_wall = [24, 0]  # X=10 X=12\n",
        "    y_wall = [12, -12]  # X=10 X=12\n",
        "    RIS_wall = 0  # ris in x\n",
        "\n",
        "    x=location_user[:, :, :, :, 0:1]\n",
        "    y=location_user[:, :, :, :, 1:2]\n",
        "    z=location_user[:, :, :, :, 2:3]\n",
        "    Refl1_user = np.zeros_like(location_user)\n",
        "    Refl1_ris_user = np.zeros_like(location_user)\n",
        "    Refl2_user = np.zeros_like(location_user)\n",
        "    Refl2_ris_user = np.zeros_like(location_user)\n",
        "    #########reflect once########################\n",
        "    for refwall in [i * 2 for i in y_wall]:\n",
        "        temp = np.concatenate((x, refwall - y, z), axis=4)\n",
        "        Refl1_user = np.concatenate((Refl1_user, temp), axis=1)\n",
        "        Refl1_ris_user = np.concatenate((Refl1_ris_user, temp), axis=1)\n",
        "    for refwall in [i * 2 for i in x_wall]:\n",
        "        temp = np.concatenate((refwall - x, y, z), axis=4)\n",
        "        Refl1_user = np.concatenate((Refl1_user, temp), axis=1)\n",
        "        if refwall == RIS_wall * 2:\n",
        "            continue\n",
        "        else:\n",
        "            Refl1_ris_user = np.concatenate((Refl1_ris_user, temp), axis=1)\n",
        "\n",
        "    Refl1_user = Refl1_user[:, 1:, :, :, :]  # remove the all zeros line\n",
        "    Refl1_ris_user = Refl1_ris_user[:, 1:, :, :, :]\n",
        "    #########reflect twice########################\n",
        "    for ref1 in [i * 2 for i in y_wall]:\n",
        "        ref2 = sum(y_wall) * 2 - ref1\n",
        "        temp = np.concatenate((x, ref2 - (ref1 - y), z), axis=4)\n",
        "        Refl2_user = np.concatenate((Refl2_user, temp), axis=1)\n",
        "        Refl2_ris_user = np.concatenate((Refl2_ris_user, temp), axis=1)\n",
        "    for ref1 in [i * 2 for i in x_wall]:\n",
        "        ref2 = sum(x_wall) * 2 - ref1\n",
        "        temp = np.concatenate((ref2 - (ref1 - x), y, z), axis=4)\n",
        "        Refl2_user = np.concatenate((Refl2_user, temp), axis=1)\n",
        "        if ref2 == RIS_wall * 2:\n",
        "            continue\n",
        "        else:\n",
        "            Refl2_ris_user = np.concatenate((Refl2_ris_user, temp), axis=1)\n",
        "    for ref1 in [i * 2 for i in x_wall]:\n",
        "        for ref2 in [i * 2 for i in y_wall]:\n",
        "            # print(ref1,ref2)\n",
        "            temp = np.concatenate((ref1 - x, ref2 - y, z), axis=4)\n",
        "            Refl2_user = np.concatenate((Refl2_user, temp), axis=1)\n",
        "            if ref1 == RIS_wall * 2:\n",
        "                # print('12334',ref1,ref2)\n",
        "                continue\n",
        "            else:\n",
        "                # print('2 \\n',np.shape(Refl2_ris_user))\n",
        "                Refl2_ris_user = np.concatenate((Refl2_ris_user, temp), axis=1)\n",
        "    Refl2_user = Refl2_user[:, 1:, :, :, :]  # remove the all zeros line\n",
        "    Refl2_ris_user = Refl2_ris_user[:, 1:, :, :, :]  # remove the all zeros line\n",
        "    # print(np.shape(location_user),np.shape(Refl1_user),np.shape(Refl2_user),np.shape(Refl1_ris_user),np.shape(Refl2_ris_user))\n",
        "    #print(Refl1_user)\n",
        "    return location_user, Refl1_user, Refl2_user, Refl1_ris_user, Refl2_ris_user\n",
        "\n",
        "\n",
        "def generate_irs_location(number_samples, num_irs=2):\n",
        "    x = np.reshape(np.array([0.0]), [1, 1, -1, 1, 1])[:, :, :num_irs, :, :]\n",
        "    y = np.reshape(np.array([0.0]), [1, 1, -1, 1, 1])[:, :, :num_irs, :, :]\n",
        "    z = 0.0 * np.ones_like(x)\n",
        "    location_bs = np.concatenate((x, y, z), axis=4) * np.ones([number_samples, 1, num_irs, 1, 3])  # (num_bs,3)\n",
        "    return location_bs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_bs_location(number_samples, num_BS):\n",
        "    x = np.reshape(np.array([12]), [1, 1, 1, 1, 1])\n",
        "    y = np.reshape(np.array([-11.5]), [1, 1, 1, 1, 1])\n",
        "    z = 0.0 * np.ones_like(x)\n",
        "    location_bs = np.concatenate((x, y, z), axis=4) * np.ones([number_samples, 1, 1, num_BS, 3])  # (num_bs,3)\n",
        "    return location_bs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def cal_angle_distance2(location1, location2):\n",
        "    distance = np.linalg.norm(location1 - location2, axis=4, keepdims=True)\n",
        "    aoa_x = (location1[:, :, :, :, 0:1] - location2[:, :, :, :, 0:1]) / distance\n",
        "    aoa_y = (location1[:, :, :, :, 1:2] - location2[:, :, :, :, 1:2]) / distance\n",
        "    aoa_z = (location1[:, :, :, :, 2:3] - location2[:, :, :, :, 2:3]) / distance\n",
        "    return aoa_x, aoa_y, aoa_z\n",
        "\n",
        "    #\n",
        "def generate_channel_fullRician(params_system,  num_samples, pathloss_irs_bs,channel_irs_user, testing=0,irs_Nh=16):\n",
        "    (num_bs, number_irs, num_elements_irs, num_user) = params_system\n",
        "    location_irs = generate_irs_location(1, number_irs)\n",
        "    #print(np.shape(location_user),'1111111111111111111111111111111111111')\n",
        "    location_bs = generate_bs_location(1, num_bs)\n",
        "    aod_irs_x,aod_irs_y,aod_irs_z=cal_angle_distance2(location_bs,location_irs)\n",
        "    #################   channel between IRS and BS  ########################\n",
        "\n",
        "    i1 = np.mod(np.arange(num_elements_irs), irs_Nh).reshape([1, 1, 1, num_elements_irs, 1])\n",
        "    i2 = np.floor(np.arange(num_elements_irs) / irs_Nh).reshape([1, 1, 1, num_elements_irs, 1])\n",
        "\n",
        "    pathloss_irs_bs = pathloss_irs_bs*np.ones([num_samples, 1, number_irs, 1, num_bs])\n",
        "    a_irs_bs = np.exp(1j * np.pi * (i1 * aod_irs_y + i2 * aod_irs_z)).reshape(1, 1, number_irs,\n",
        "                                                                              num_elements_irs, num_bs)\n",
        "    channel_bs_irs = (a_irs_bs.conjugate() * pathloss_irs_bs)\n",
        "\n",
        "    ###############################################################################################\n",
        "    channel_bs_irs_user = channel_bs_irs * channel_irs_user\n",
        "\n",
        "    #channel_bs_user= np.sum(channel_bs_user, 1, keepdims=True)\n",
        "\n",
        "    channels =channel_bs_irs_user\n",
        "\n",
        "    aoa_aod = (aod_irs_x,aod_irs_y, aod_irs_z )\n",
        "    return channels, aoa_aod\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import scipy.io\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dense\n",
        "# from wsr.bcd.generate_received_pilots import generate_received_pilots_batch\n",
        "\n",
        "\n",
        "# these three lines are needed if using google colab, otherwise can delete\n",
        "\n",
        "\n",
        "\n",
        "'System Information'\n",
        "N = 1  # Number of BS's antennas\n",
        "delta_inv = 128  # Number of posterior intervals inputed to DNN\n",
        "\n",
        "\n",
        "tau = 2  # Pilot length\n",
        "scale_factor=100\n",
        "snr_const1 = 25  # The SNR\n",
        "snr_const = np.array([snr_const1])\n",
        "Pvec = 10 ** (snr_const / 10)  # Set of considered TX powers\n",
        "\n",
        "mean_true_alpha = 0.0 + 0.0j  # Mean of the fading coefficient\n",
        "std_per_dim_alpha = np.sqrt(0.5)  # STD of the Gaussian fading coefficient per real dim.\n",
        "noiseSTD_per_dim = np.sqrt(0.5)  # STD of the Gaussian noise per real dim.\n",
        "#####################################################\n",
        "'RIS'\n",
        "num_ris = 1\n",
        "N_ris = 64\n",
        "num_users = 1\n",
        "\n",
        "location_user = None\n",
        "N_base = 1\n",
        "params_system = (N_base, num_ris, N_ris, num_users)  # (num_bs, num_elements_irs, num_user)\n",
        "input_mode = 1\n",
        "#####################################################\n",
        "'Learning Parameters'\n",
        "batch_size_order = 8  # Mini_batch_size = batch_size_order*delta_inv\n",
        "\n",
        "train_num=batch_size_order * delta_inv\n",
        "initial_run = 1  # 0: Continue training; 1: Starts from the scratch\n",
        "if initial_run == 1:\n",
        "    print('!!!!! training from scratch !!!!!')\n",
        "n_epochs = 1000  # Num of epochs\n",
        "learning_rate = 0.00005  # Learning rate\n",
        "batch_per_epoch = 100  # Number of mini batches per epoch\n",
        "\n",
        "val_size_order = 8  # Validation_set_size = val_size_order*delta_inv\n",
        "test_size_order = 782  # Test_set_size = test_size_order*delta_inv*scale_factor\n",
        "######################################################\n",
        "tf.reset_default_graph()  # Reseting the graph\n",
        "he_init = tf.variance_scaling_initializer()  # Define initialization method\n",
        "######################################## Place Holders\n",
        "# alpha_input = tf.placeholder(tf.float32, shape=(None,1), name=\"alpha_input\")\n",
        "\n",
        "# alpha_input = tf.placeholder(tf.float32, shape=(None,1), name=\"alpha_input\")\n",
        "loc_input = tf.placeholder(tf.float32, shape=(None, 3), name=\"loc_input\")\n",
        "\n",
        "channel_bs_irs_user = tf.placeholder(tf.complex64, shape=(None, num_users, num_ris, N_ris, 1), name=\"channel_irs_user\")\n",
        "\n",
        "channel_bs_irs_user2=tf.reshape(channel_bs_irs_user,(-1,1, num_users, num_ris, N_ris, 1))\n",
        "\n",
        "channel_bs_user = tf.placeholder(tf.complex64, shape=(None,   N_base), name=\"channel_bs_user\")\n",
        "\n",
        "beamform_time= int(18/tau)\n",
        "#########################################################################################################################\n",
        "# Constructing the array responses for AoA samples\n",
        "##################### NETWORK############################################################################################\n",
        "with tf.name_scope(\"array_response_construction\"):\n",
        "    lay = {}\n",
        "\n",
        "    lay['P'] = tf.constant(1.0)*Pvec\n",
        "    ###############\n",
        "    from0toN = tf.cast(tf.range(0, N, 1), tf.float32)\n",
        "\n",
        "with tf.name_scope(\"channel_sensing\"):\n",
        "    hidden_size = 431\n",
        "    A1 = tf.get_variable(\"A1\", shape=[hidden_size, hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    A2 = tf.get_variable(\"A2\", shape=[hidden_size*2, hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    A3 = tf.get_variable(\"A3\", shape=[hidden_size*2, hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    A4 = tf.get_variable(\"A4\", shape=[hidden_size*2, 2 * N_ris * num_ris*beamform_time], dtype=tf.float32, initializer=he_init)\n",
        "\n",
        "    b1 = tf.get_variable(\"b1\", shape=[hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    b2 = tf.get_variable(\"b2\", shape=[hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    b3 = tf.get_variable(\"b3\", shape=[hidden_size*2], dtype=tf.float32, initializer=he_init)\n",
        "    b4 = tf.get_variable(\"b4\", shape=[2 * N_ris * num_ris*beamform_time], dtype=tf.float32, initializer=he_init)\n",
        "\n",
        "    w_dict = []\n",
        "    posterior_dict = []\n",
        "    idx_est_dict = []\n",
        "    layer_Ui = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Wi = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Uf = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Wf = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Uo = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Wo = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Uc = Dense(units=hidden_size, activation='linear')\n",
        "    layer_Wc = Dense(units=hidden_size, activation='linear')\n",
        "\n",
        "\n",
        "    def RNN(input_x, h_old, c_old):\n",
        "        i_t = tf.sigmoid(layer_Ui(input_x) + layer_Wi(h_old))\n",
        "        f_t = tf.sigmoid(layer_Uf(input_x) + layer_Wf(h_old))\n",
        "        o_t = tf.sigmoid(layer_Uo(input_x) + layer_Wo(h_old))\n",
        "        c_t = tf.tanh(layer_Uc(input_x) + layer_Wc(h_old))\n",
        "        c = i_t * c_t + f_t * c_old  # cell state\n",
        "        h_new = o_t * tf.tanh(c)  # hidden state\n",
        "        return h_new, c\n",
        "\n",
        "\n",
        "    snr = lay['P'] * tf.ones(shape=[tf.shape(loc_input)[0], 1], dtype=tf.float32)\n",
        "\n",
        "    all_output = tf.zeros(shape=[tf.shape(loc_input)[0], 1], dtype=tf.float32)\n",
        "    all_output2 = tf.zeros(shape=[tf.shape(loc_input)[0], 1], dtype=tf.float32)\n",
        "    y_real_all=tf.zeros(shape=[tf.shape(loc_input)[0], beamform_time], dtype=tf.float32)\n",
        "    theta_final=tf.zeros(shape=[tf.shape(loc_input)[0],beamform_time, N_ris * num_ris], dtype=tf.complex64)\n",
        "    for t in range(tau):\n",
        "        'DNN designs the next sensing direction'\n",
        "        if t == 0:\n",
        "            RSS_val = tf.ones([tf.shape(loc_input)[0], beamform_time*2])\n",
        "            Dif_y = tf.zeros([tf.shape(loc_input)[0], beamform_time*2])\n",
        "            h_old = tf.zeros([tf.shape(loc_input)[0], hidden_size])\n",
        "            c_old = tf.zeros([tf.shape(loc_input)[0], hidden_size])\n",
        "        # print(tf.shape(RSS_val))\n",
        "\n",
        "\n",
        "        if input_mode==2:\n",
        "          h_old, c_old = RNN(tf.concat([RSS_val,Dif_y],axis=1), h_old, c_old)\n",
        "        else:\n",
        "          h_old, c_old = RNN(tf.concat([RSS_val],axis=1), h_old, c_old)\n",
        "        x1 = tf.nn.relu(h_old @ A1 + b1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x2 = tf.nn.relu(x1 @ A2 + b2)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x3 = tf.nn.relu(x2 @ A3 + b3)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        '''\n",
        "            RIS implementation\n",
        "        '''\n",
        "        ris_her_unnorm = x3 @ A4 + b4\n",
        "        ris_her_unnorm = tf.reshape(ris_her_unnorm,[-1,beamform_time,2 * N_ris * num_ris])\n",
        "        ris_her_r = ris_her_unnorm[:,:, 0:N_ris * num_ris]\n",
        "        ris_her_i = ris_her_unnorm[:,:, N_ris * num_ris:2 * N_ris * num_ris]  # (? , N_ris)\n",
        "        theta_tmp = tf.sqrt(tf.square(ris_her_r) + tf.square(ris_her_i))  # (? , N_ris)\n",
        "        theta_real = ris_her_r / theta_tmp  # (? , N_ris)\n",
        "        theta_imag = ris_her_i / theta_tmp  # (? , N_ris)\n",
        "        #theta_temp=tf.concat([ theta_real[:,:] , theta_imag[:,:]], axis=1)\n",
        "        theta_temp=tf.complex(theta_real, theta_imag)\n",
        "        theta_final=  tf.concat([theta_final ,theta_temp], axis=0)\n",
        "        #print(theta)                     #  (?, 1, 128)\n",
        "        theta_real = tf.reshape(theta_real, [-1,beamform_time, 1, num_ris, N_ris, 1])\n",
        "        theta_imag = tf.reshape(theta_imag, [-1,beamform_time, 1, num_ris, N_ris, 1])\n",
        "        'BS observes the next measurement'\n",
        "        theta=tf.complex(theta_real,theta_imag)\n",
        "        h_d_plus_h_cas = tf.reduce_sum(channel_bs_irs_user2 * theta,\n",
        "                                   (2, 3,4))  # since\n",
        "        h_d_plus_h_cas=tf.reshape(h_d_plus_h_cas,[tf.shape(loc_input)[0],beamform_time*1])+channel_bs_user\n",
        "        #import tensorflow as tf2\n",
        "        #tf2.random.set_seed(0)\n",
        "        noise = tf.complex(tf.random_normal(tf.shape(h_d_plus_h_cas), mean=0.0, stddev=noiseSTD_per_dim), \\\n",
        "                           tf.random_normal(tf.shape(h_d_plus_h_cas), mean=0.0, stddev=noiseSTD_per_dim))\n",
        "        #y_complex = tf.complex(tf.sqrt(lay['P']), 0.0) * h_d_plus_h_cas + noise\n",
        "        noise1=noise/ tf.complex(tf.sqrt(lay['P']), 0.0)\n",
        "        #noise1=noise1/1000\n",
        "        #if t == 0:\n",
        "         # noise_init = tf.complex(tf.random_normal(tf.shape(h_d_plus_h_cas), mean=0.0, stddev=noiseSTD_per_dim), \\\n",
        "         #                  tf.random_normal(tf.shape(h_d_plus_h_cas), mean=0.0, stddev=noiseSTD_per_dim))\n",
        "         # y_init=channel_bs_user+noise_init\n",
        "        y_complex = h_d_plus_h_cas + noise1\n",
        "        y_real_all= tf.concat([y_real_all,tf.abs(y_complex)],0)\n",
        "        #Dif_y= tf.concat( [  tf.real(y_complex-y_init ), tf.imag(y_complex-y_init )],axis=1)\n",
        "        #RSS_val = tf.abs(y_complex*tf.complex(tf.sqrt(lay['P']), 0.0))\n",
        "        RSS_val =tf.concat( [tf.real(y_complex ), tf.imag(y_complex )],axis=1)\n",
        "    # h_old, c_old = RNN(tf.concat([RSS_val,Dif_y],axis=1), h_old, c_old)\n",
        "\n",
        "\n",
        "\n",
        "    h_old, c_old = RNN(tf.concat([RSS_val],axis=1), h_old, c_old)\n",
        "    loc_hat = Dense(units=3, activation='linear')(c_old)\n",
        "    y_real_all=y_real_all[1:,:]\n",
        "    theta_final=theta_final[1:,:,:]\n",
        "\n",
        "################################### Loss Function##################################################################\n",
        "a = tf.math.reduce_euclidean_norm(loc_input[:, :] - loc_input[:, :], 1)\n",
        "b = tf.math.reduce_euclidean_norm(loc_hat - loc_input[:, :], 1)\n",
        "loss = tf.keras.losses.mean_squared_error(a, b)\n",
        "\n",
        "####### Optimizer\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        " #########################################################################\n",
        "# print(wavelength)\n",
        "\n",
        "power_bs_irs=-72.129+scale_factor\n",
        "phase_bs_irs=159.36\n",
        "power_bs_irs=10**(power_bs_irs/10);\n",
        "pathloss_bs_irs=np.sqrt(power_bs_irs)*np.exp(1j*(phase_bs_irs/180*np.pi))\n",
        "\n",
        "training=1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_save_path ='/content/drive/MyDrive/data1/'\n",
        "\n",
        "# Load the .mat file\n",
        "if training==1:\n",
        "    Train_location_user = sio.loadmat(drive_save_path+'location_user.mat')['location_user']\n",
        "    Val_location_user=sio.loadmat(drive_save_path+'location_user_val.mat')['location_user']\n",
        "    Train_channel_irs_user =(sio.loadmat(drive_save_path+'channel_irs_user_romdp_ref5.mat')['channel_irs_user']).reshape(-1,1,1,64,1)\n",
        "    Val_channel_irs_user=(sio.loadmat(drive_save_path+'channel_irs_user_val_romdp_ref5.mat')['channel_irs_user']).reshape(-1,1,1,64,1)\n",
        "    Train_channel_bs_user=sio.loadmat(drive_save_path+'bs_user_variables.mat')['channel_bs_user']\n",
        "    Val_channel_bs_user=sio.loadmat(drive_save_path+'bs_user_variables_val.mat')['channel_bs_user']\n",
        "     #(params_system,  num_samples, pathloss_irs_bs,channel_irs_user, testing=0,irs_Nh=16):\n",
        "    #1, 1, 1, num_elements_irs, 1\n",
        "    num_val=1000\n",
        "\n",
        "\n",
        "else:\n",
        "    Val_location_user=sio.loadmat(drive_save_path+'location_user_test.mat')['location_user']\n",
        "    Val_channel_irs_user=(sio.loadmat(drive_save_path+'channel_irs_user_test_romdp_ref5.mat')['channel_irs_user']).reshape(-1,1,1,64,1)\n",
        "    Val_channel_bs_user=sio.loadmat(drive_save_path+'bs_user_variables_test.mat')['channel_bs_user']\n",
        "    num_val=10000\n",
        "    #print(Val_location_user)\n",
        "###########  Validation Setgenerate_channel_fullRician(params_system,multipath,num_samples,wavelength,location_irs=np.array([0, 0, 0]), scale_factor=100,irs_Nh = 16):\n",
        "channels_val,aoa_aod= generate_channel_fullRician(params_system,  num_val, pathloss_bs_irs,Val_channel_irs_user)\n",
        "channel_bs_irs_user_val=channels_val\n",
        "feed_dict_val = {loc_input: np.array(Val_location_user),\n",
        "                 channel_bs_irs_user: channel_bs_irs_user_val,\n",
        "                 channel_bs_user:Val_channel_bs_user}\n",
        "#########################################   Training ##############################################################\n",
        "Ris = '/RIS' + str(num_ris) + '_mode' + str(input_mode)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "#drive_save_path = './My_code_new/'+'mode'+str(input_mode)\n",
        "\n",
        "file_name = drive_save_path + \"/snr\"+str(snr_const1)+\"_sf\"+str(scale_factor)+\"_beam\"+str(beamform_time)+\"_tau\"+str(tau)\n",
        "if training==1:\n",
        "    def mkdir(path):\n",
        "        folder = os.path.exists(path)\n",
        "\n",
        "        if not folder:  #\n",
        "            os.makedirs(path)  # makedirs\n",
        "            print(\"create new folder\")\n",
        "        else:\n",
        "            print('exist folder')\n",
        "    with tf.Session() as sess:\n",
        "        # if initial_run == 1:\n",
        "        init.run()\n",
        "        #saver.restore(sess, file_name + Ris + '/Tau_' + str(tau) + '_snr_' + str(snr_const[0]))\n",
        "        # else:\n",
        "        best_loss = 1000000\n",
        "\n",
        "        print(tf.test.is_gpu_available())  # Prints whether or not GPU is on\n",
        "\n",
        "        mkdir(file_name)\n",
        "\n",
        "        for epoch in range(10000):\n",
        "            batch_iter = 0\n",
        "            for rnd_indices in range(batch_per_epoch):\n",
        "                num_samples=batch_size_order * delta_inv\n",
        "                choice=np.random.randint(10**6, size=[num_samples])\n",
        "                Train_channel_irs_user_epoch=Train_channel_irs_user[choice,:,:].reshape(num_samples,1,1,64,1)\n",
        "                channels_train,_= generate_channel_fullRician(params_system,num_samples,pathloss_bs_irs,Train_channel_irs_user_epoch)\n",
        "                channel_bs_irs_user_train=channels_train\n",
        "\n",
        "                feed_dict_batch = {loc_input: Train_location_user[choice,:],\n",
        "                                   channel_bs_irs_user: channel_bs_irs_user_train,\n",
        "                                   channel_bs_user:Train_channel_bs_user[choice,:]}\n",
        "                _,train_loss=sess.run([training_op,loss], feed_dict=feed_dict_batch)\n",
        "                batch_iter += 1\n",
        "\n",
        "            power_val,loss_val  = sess.run([lay['P'],loss ], feed_dict=feed_dict_val)\n",
        "            if epoch % 20 == 0:  # Every 10 iterations it checks if the validation performxZxxZZace is improved, then saves parameters\n",
        "                print('epoch', epoch, '  loss_test:%2.5f' % loss_val, '  best_test:%2.5f' % best_loss,'  sqrt_loss_test:%2.5f' % np.sqrt(loss_val), '  sqrt_best_test:%2.5f' %  np.sqrt(best_loss))\n",
        "                print('train_loss',train_loss)\n",
        "                if loss_val < best_loss:\n",
        "                  save_path = saver.save(sess, file_name + Ris + '/Tau2_' + str(tau) + '_snr_' + str(snr_const[0]))\n",
        "                  best_loss = loss_val\n",
        "                if epoch%800==0:\n",
        "                  save_path = saver.save(sess, file_name + Ris + '/Tau2_' + str(tau) + '_snr_' + str(snr_const[0])+str(epoch))\n",
        "                with open( file_name + Ris +'/data.txt', 'a') as f:\n",
        "                  print('epoch', epoch, '  loss_test:%2.5f' % loss_val, '  best_test:%2.5f' % best_loss, '  sqrt_loss_test:%2.5f' % np.sqrt(loss_val), '  sqrt_best_test:%2.5f' %  np.sqrt(best_loss),file = f)\n",
        "#################################   TEST ######################\n",
        "\n",
        "\n",
        "import os\n",
        "import scipy.io as sio\n",
        "\n",
        "\n",
        "\n",
        "Ris = '/RIS' + str(num_ris) + '_mode' + str(input_mode)\n",
        "\n",
        "drive_save_path = './My_code/'\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    #init.run()\n",
        "    val_number=10000\n",
        "    init_num=0\n",
        "    saver.restore(sess, file_name + Ris + '/Tau2_' + str(tau) + '_snr_' + str(snr_const[0]))\n",
        "\n",
        "\n",
        "    '''\n",
        "        RIS implementation\n",
        "    '''\n",
        "\n",
        "      # (aoa_bs, aoa_bs_y, aoa_bs_z, aod_irs_y, aod_irs_z, aoa_irs_y, aoa_irs_z)\n",
        "    #channel_true_test,aoa_aod = generate_channel_fullRician(params_system,val_number-init_num,pathloss_bs_irs,Val_channel_irs_user)\n",
        "    (aod_irs_x,aod_irs_y, aod_irs_z)= aoa_aod\n",
        "    #( channel_bs_user_test,channel_irs_user_test, channel_bs_user_test) = channel_true_test\n",
        "    #(channel_bs_user,channel_irs_user, channel_bs_irs)\n",
        "    #print('locaion',Val_location_user)\n",
        "\n",
        "    #(location_user, location_virtual_user, lvu, ris_user1, ris_user2)=location\n",
        "    #print(\"aod_irs_y:\",aod_irs_y,'\\n',\"aod_irs_z:\",aod_irs_z,'\\n',\"aoa_irs_y:\",aoa_irs_y,'\\n',\"aoa_irs_z:\",aoa_irs_z)\n",
        "    print(\"aod_irs_y:\",aod_irs_y,'\\n',\"aod_irs_z:\",aod_irs_z,'\\n')\n",
        "    feed_dict_batch = {loc_input: np.array(Val_location_user[init_num:val_number,:]),\n",
        "                       channel_bs_irs_user: channel_bs_irs_user_val[init_num:val_number,:,:,:,:],\n",
        "                       channel_bs_user:Val_channel_bs_user[init_num:val_number,:]}\n",
        "    mse_loss,theta_test,y_real_value,value,noise_value= sess.run([loss,theta_final,y_real_all, h_d_plus_h_cas , noise1 ],feed_dict=feed_dict_batch)\n",
        "    #print(np.abs(value))\n",
        "    #print('noise:',np.abs(noise_value))\n",
        "    #print(y_real_value,\"y_real_value\")\n",
        "    location=Val_location_user[init_num:val_number,:]\n",
        "    location_user, location_virtual_user, lvu, ris_user1, ris_user2=generate_user_location(val_number, val_number-init_num,location.reshape(val_number-init_num, 1, 1, 1, 3))\n",
        "    data = {'theta': theta_test,'location':location,'location_virtual_user':location_virtual_user,'lvu':lvu,'ris_user1':ris_user1,'ris_user2':ris_user2}\n",
        "    sio.savemat(file_name + Ris + '/file2_50_nocint.mat', data)\n",
        "   # print(y_real_value)\n",
        "   # print(np.mean(theta_test,0))io.s\n",
        "    print('loss',np.sqrt(mse_loss))\n",
        "    with open( file_name + Ris +'/data.txt', 'a') as f:\n",
        "      print('loss',np.sqrt(mse_loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ov2Grqkesrmx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}